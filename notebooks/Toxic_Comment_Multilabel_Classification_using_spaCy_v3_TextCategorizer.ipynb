{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Multilabel Classification using spaCy v3 TextCategorizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T0M5w6cya39",
        "outputId": "fe80e9cd-5c6d-49be-dbd3-20178a622a3d"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "!pip install typer\n",
        "#!pip install spacy[cuda110]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.2)\n",
            "Collecting thinc<8.1.0,>=8.0.8\n",
            "  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
            "\u001b[K     |████████████████████████████████| 623 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 34.2 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 25.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.0 pydantic-1.8.2 spacy-3.1.2 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 typer-0.3.2\n",
            "Collecting en-core-web-lg==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0-py3-none-any.whl (777.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 777.1 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.1.0) (3.1.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.62.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs8zORQKzznx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34901cd2-1f2e-4ee7-d7d3-d11e3def6774"
      },
      "source": [
        "import spacy\n",
        "import srsly\n",
        "import pandas as pd\n",
        "spacy.prefer_gpu()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms4Miepu0cnR",
        "outputId": "26961153-8a69-494f-e847-3226d95fc367"
      },
      "source": [
        "# download training set\n",
        "!wget https://raw.githubusercontent.com/tianqwang/Toxic-Comment-Classification-Challenge/master/data/train.csv train.csv\n",
        "\n",
        "# download test set\n",
        "!wget https://raw.githubusercontent.com/tianqwang/Toxic-Comment-Classification-Challenge/master/data/test.csv test.csv\n",
        "\n",
        "# download script converting jsonl to .spacy format\n",
        "!wget https://raw.githubusercontent.com/explosion/projects/v3/pipelines/textcat_multilabel_demo/scripts/convert.py "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-18 13:43:47--  https://raw.githubusercontent.com/tianqwang/Toxic-Comment-Classification-Challenge/master/data/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68802655 (66M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  65.62M   163MB/s    in 0.4s    \n",
            "\n",
            "2021-09-18 13:43:48 (163 MB/s) - ‘train.csv’ saved [68802655/68802655]\n",
            "\n",
            "--2021-09-18 13:43:48--  http://train.csv/\n",
            "Resolving train.csv (train.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘train.csv’\n",
            "FINISHED --2021-09-18 13:43:48--\n",
            "Total wall clock time: 1.4s\n",
            "Downloaded: 1 files, 66M in 0.4s (163 MB/s)\n",
            "--2021-09-18 13:43:48--  https://raw.githubusercontent.com/tianqwang/Toxic-Comment-Classification-Challenge/master/data/test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60354593 (58M) [text/plain]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]  57.56M   126MB/s    in 0.5s    \n",
            "\n",
            "2021-09-18 13:43:50 (126 MB/s) - ‘test.csv’ saved [60354593/60354593]\n",
            "\n",
            "--2021-09-18 13:43:50--  http://test.csv/\n",
            "Resolving test.csv (test.csv)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘test.csv’\n",
            "FINISHED --2021-09-18 13:43:50--\n",
            "Total wall clock time: 1.3s\n",
            "Downloaded: 1 files, 58M in 0.5s (126 MB/s)\n",
            "--2021-09-18 13:43:50--  https://raw.githubusercontent.com/explosion/projects/v3/pipelines/textcat_multilabel_demo/scripts/convert.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 512 [text/plain]\n",
            "Saving to: ‘convert.py’\n",
            "\n",
            "convert.py          100%[===================>]     512  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-18 13:43:50 (14.9 MB/s) - ‘convert.py’ saved [512/512]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b37okeKV1BVm"
      },
      "source": [
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "def df_csv_to_jsonl(df, output_path):\n",
        "    x = list(df['comment_text'].to_dict().values())\n",
        "    y = df[labels].to_dict(orient='records')\n",
        "\n",
        "    data = [{\"text\": _x, \"cats\": _y} for _x, _y in zip(x, y)]\n",
        "    srsly.write_jsonl(output_path, data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HinAtDQJGta_"
      },
      "source": [
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# split train_df into train and val df\n",
        "train = train_df.sample(frac=0.8)\n",
        "validation = train_df.drop(train.index)\n",
        "\n",
        "# convert from dataframe to jsonl\n",
        "df_csv_to_jsonl(train, \"./train.json\")\n",
        "df_csv_to_jsonl(validation, \"./validation.json\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_d1FX0eLQPd"
      },
      "source": [
        "#### Convert JSONL to .spaCy format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqoIGBz3LKXo"
      },
      "source": [
        "!python convert.py en ./train.json ./train.spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OJ-jXeOK6DZ"
      },
      "source": [
        "!python convert.py en ./validation.json ./validation.spacy"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mufwJOseImNI"
      },
      "source": [
        "#### Generate config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRROIn7LBL-K",
        "outputId": "d695cc62-58ab-42f4-fda9-9535a9ffb3b7"
      },
      "source": [
        "!python -m spacy init config --lang en --pipeline textcat_multilabel configs/config.cfg --force --optimize accuracy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: textcat_multilabel\n",
            "- Optimize for: accuracy\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "configs/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8TxjP3LGOr"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCiSyLkXRwyk"
      },
      "source": [
        "# edit config\n",
        "# --components.tok2vec.model.encode.width 32 --components.tok2vec.model.encode.depth 5\n",
        "# --nlp.batch_size 32 --training.batcher.start 32 --training.batcher.stop 128\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE57Xzsd1nVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7b6ef9-3c17-4bf0-cf57-382ce3dc515b"
      },
      "source": [
        "!python -m spacy train configs/config.cfg --output models/ --paths.train ./train.spacy --paths.dev ./validation.spacy --gpu-id 0 --components.tok2vec.model.encode.width 32 --components.tok2vec.model.encode.depth 5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: models\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-09-18 14:09:46,993] [INFO] Set up nlp object from config\n",
            "[2021-09-18 14:09:47,008] [INFO] Pipeline: ['tok2vec', 'textcat_multilabel']\n",
            "[2021-09-18 14:09:47,013] [INFO] Created vocabulary\n",
            "[2021-09-18 14:10:19,249] [INFO] Added vectors: en_core_web_lg\n",
            "tcmalloc: large alloc 1643593728 bytes == 0x564ee1a80000 @  0x7f2bcbcec2a4 0x7f2bba27fcb0 0x7f2bba289083 0x7f2bba28887b 0x7f2bba285de1 0x7f2bba2866de 0x564e618c42ed 0x564e619b5e1d 0x564e61937e99 0x564e619329ee 0x564e618c5bda 0x564e61934737 0x7f2a80af1918 0x7f2a80af31fe 0x7f2a80af8947 0x7f2a80af9d42 0x564e618c4c52 0x564e61937c25 0x564e618c5afa 0x564e61933915 0x7f2a80af1918 0x7f2a80af31fe 0x7f2a80af8470 0x564e618c44b0 0x564e619b5e1d 0x564e61937e99 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda\n",
            "tcmalloc: large alloc 1662509056 bytes == 0x564ee1a80000 @  0x7f2bcbcec2a4 0x7f2bba27fcb0 0x7f2bba286fcb 0x7f2bba28887b 0x7f2bba285de1 0x7f2bba2866de 0x564e618c42ed 0x564e619b5e1d 0x564e61937e99 0x564e619329ee 0x564e618c5bda 0x564e61934737 0x564e618c5afa 0x564e61937d00 0x7f2a80af1918 0x7f2a80af31fe 0x7f2a80af8470 0x564e618c44b0 0x564e619b5e1d 0x564e61937e99 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e619329ee 0x564e61804e2b\n",
            "[2021-09-18 14:10:21,454] [INFO] Finished initializing nlp object\n",
            "tcmalloc: large alloc 2147491840 bytes == 0x564f10aca000 @  0x7f2bcbcec2a4 0x564e618c14cc 0x564e6187cc32 0x564e61a27f8d 0x564e618c446c 0x564e618c4240 0x564e619380f3 0x564e618c5afa 0x564e61933c0d 0x564e618c5afa 0x564e61933c0d 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x7f2a80a4f1e6 0x564e618052eb 0x7f2a80a4d703 0x564e618c44b0 0x564e618c4240 0x564e61937973 0x564e61932ced 0x564e618c648c 0x564e618c6698 0x564e61934fe4 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda\n",
            "tcmalloc: large alloc 2147491840 bytes == 0x564f10aca000 @  0x7f2bcbcec2a4 0x564e618c14cc 0x564e6187cc32 0x564e61a27f8d 0x564e618c446c 0x564e618c4240 0x564e619380f3 0x564e618c5afa 0x564e61933c0d 0x564e618c5afa 0x564e61933c0d 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e6199c96d 0x564e61933daf 0x564e61932ced 0x564e618c648c 0x564e618c6698 0x564e61934fe4 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e619329ee 0x564e61804e2b 0x564e61934fe4\n",
            "tcmalloc: large alloc 2147491840 bytes == 0x564f10aca000 @  0x7f2bcbcec2a4 0x564e618c14cc 0x564e6187cc32 0x564e61a27f8d 0x564e618c446c 0x564e618c4240 0x564e619380f3 0x564e618c5afa 0x564e61933c0d 0x564e618c5afa 0x564e61933c0d 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x7f2a80a4f1e6 0x564e618052eb 0x7f2a80a4d703 0x564e618c44b0 0x564e618c4240 0x564e61937973 0x564e61932ced 0x564e618c648c 0x564e618c6698 0x564e61934fe4 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda\n",
            "tcmalloc: large alloc 2147491840 bytes == 0x564f10aca000 @  0x7f2bcbcec2a4 0x564e618c14cc 0x564e6187cc32 0x564e61a27f8d 0x564e618c446c 0x564e618c4240 0x564e619380f3 0x564e618c5afa 0x564e61933c0d 0x564e618c5afa 0x564e61933c0d 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e61933daf 0x564e619b6cf8 0x564e61933daf 0x564e61932ced 0x564e618c648c 0x564e618c6698 0x564e61934fe4 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e61932ced 0x564e618c5bda 0x564e61934737 0x564e619329ee 0x564e61804e2b 0x564e61934fe4 0x564e61932ced\n",
            "[2021-09-18 14:15:16,373] [INFO] Initialized pipeline components: ['tok2vec', 'textcat_multilabel']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'textcat_multilabel']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS TEXTC...  CATS_SCORE  SCORE \n",
            "---  ------  ------------  -------------  ----------  ------\n",
            "  0       0          0.01           1.36       52.62    0.53\n",
            "  0     200          0.05          25.18       57.46    0.57\n",
            "/usr/local/lib/python3.7/dist-packages/thinc/backends/ops.py:576: RuntimeWarning: overflow encountered in exp\n",
            "  return cast(FloatsType, 1.0 / (1.0 + self.xp.exp(-X)))\n",
            "  0     400          0.01          21.87       66.75    0.67\n",
            "  0     600          0.02          18.62       60.84    0.61\n",
            "  0     800          0.04          21.58       71.62    0.72\n",
            "  0    1000          0.03           6.07       85.98    0.86\n",
            "  0    1200          0.02           6.37       86.30    0.86\n",
            "  0    1400          0.05          11.17       83.14    0.83\n",
            "  0    1600          0.03           5.36       90.03    0.90\n",
            "  0    1800          0.02           7.76       88.94    0.89\n",
            "  0    2000          0.03           1.00       92.45    0.92\n",
            "  0    2200          0.03           2.94       94.28    0.94\n",
            "  0    2400          0.01           1.93       90.65    0.91\n",
            "  0    2600          0.01           0.31       94.93    0.95\n",
            "  0    2800          0.01           3.22       94.22    0.94\n",
            "  0    3000          0.01           4.82       91.73    0.92\n",
            "  0    3200          0.01           1.19       93.78    0.94\n",
            "  0    3400          0.01           0.70       92.64    0.93\n",
            "  0    3600          0.01           0.43       92.29    0.92\n",
            "  0    3800          0.01           0.56       90.58    0.91\n",
            "  0    4000          0.01           0.17       94.06    0.94\n",
            "  0    4200          0.01           2.95       92.80    0.93\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmyKmhOfLXJ3",
        "outputId": "7bdf318b-d407-443b-b660-f90b3275b4df"
      },
      "source": [
        "!python -m spacy evaluate ./models/model-last/ ./validation.spacy --gpu-id -1 --output evaluate.json"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/thinc/backends/ops.py:576: RuntimeWarning: overflow encountered in exp\n",
            "  return cast(FloatsType, 1.0 / (1.0 + self.xp.exp(-X)))\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK                   100.00\n",
            "TEXTCAT (macro AUC)   92.80 \n",
            "SPEED                 57923 \n",
            "\n",
            "\u001b[1m\n",
            "=========================== Textcat F (per label) ===========================\u001b[0m\n",
            "\n",
            "                    P       R       F\n",
            "toxic           85.53   71.04   77.61\n",
            "severe_toxic    65.85    8.28   14.71\n",
            "obscene         79.43   79.25   79.34\n",
            "threat           0.00    0.00    0.00\n",
            "insult          69.75   71.59   70.66\n",
            "identity_hate   66.67    0.73    1.44\n",
            "\n",
            "\u001b[1m\n",
            "======================== Textcat ROC AUC (per label) ========================\u001b[0m\n",
            "\n",
            "                ROC AUC\n",
            "toxic              0.98\n",
            "severe_toxic       0.98\n",
            "obscene            0.99\n",
            "threat             0.71\n",
            "insult             0.98\n",
            "identity_hate      0.94\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to evaluate.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdfN3E1Md3Pb"
      },
      "source": [
        "nlp = spacy.load(\"./models/model-last/\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZxfXr5Qdert",
        "outputId": "34c14e78-600b-447c-b97d-836929c3d509"
      },
      "source": [
        "for idx, row in test_df.iterrows():\n",
        "    sentence = row['comment_text']\n",
        "    doc = nlp(sentence)\n",
        "    y_pred = {label: pred_prob >= 0.5 for label, pred_prob in doc.cats.items()}\n",
        "    print(f\"\\n\\n[Sentence]: \\n\\t{sentence}\")\n",
        "    print(f\"\\n[Predicted]: \\n\\t {y_pred}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    if idx >= 15:\n",
        "        break\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tYo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': True, 'severe_toxic': False, 'obscene': True, 'threat': False, 'insult': True, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t== From RfC == \n",
            "\n",
            " The title is fine as it is, IMO.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t\" \n",
            "\n",
            " == Sources == \n",
            "\n",
            " * Zawe Ashton on Lapland —  /  \"\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t:If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI don't anonymously edit articles at all.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tThank you for understanding. I think very highly of you and would not revert without discussion.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tPlease do not add nonsense to Wikipedia. Such edits are considered vandalism and quickly undone. If you would like to experiment, please use the sandbox instead. Thank you.   -\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t:Dear god this site is horrible.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t\" \n",
            " Only a fool can believe in such numbers. \n",
            " The correct number lies between 10 000 to 15 000. \n",
            " Ponder the numbers carefully.  \n",
            "\n",
            " This error will persist for a long time as it continues to reproduce... The latest reproduction I know is from ENCYCLOPÆDIA BRITANNICA ALMANAC 2008 wich states \n",
            " Magnittude: 8.7 (fair enough) \n",
            " victims: 70 000 (today 10 000 to 15 000 is not \"\"a lot\"\" so I guess people just come out with a number that impresses enough, I don't know. But I know this: it's just a shameless lucky number that they throw in the air. \n",
            " GC \n",
            "\n",
            " \"\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t== Double Redirects == \n",
            "\n",
            " When fixing double redirects, don't just blank the outer one, you need edit it to point it to the final target, unless you think it's inappropriate, in which case, it needs to be nominated at WP:RfD\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI think its crap that the link to roggenbier is to this article. Somebody that knows how to do things should change it.\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t\"::: Somebody will invariably try to add Religion?  Really??  You mean, the way people have invariably kept adding \"\"Religion\"\" to the Samuel Beckett infobox?  And why do you bother bringing up the long-dead completely non-existent \"\"Influences\"\" issue?  You're just flailing, making up crap on the fly. \n",
            " ::: For comparison, the only explicit acknowledgement in the entire Amos Oz article that he is personally Jewish is in the categories!    \n",
            "\n",
            " \"\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t, 25 February 2010 (UTC) \n",
            "\n",
            " :::Looking it over, it's clear that  (a banned sockpuppet of ) ignored the consensus (&, fwiw, policy-appropriate) choice to leave the page at Chihuahua (Mexico) and the current page should be returned there. Anyone have the time to fix the incoming links? -  18:24\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t\" \n",
            "\n",
            " It says it right there that it IS a type. The \"\"Type\"\" of institution is needed in this case because there are three levels of SUNY schools: \n",
            " -University Centers and Doctoral Granting Institutions \n",
            " -State Colleges \n",
            " -Community Colleges. \n",
            "\n",
            " It is needed in this case to clarify that UB is a SUNY Center. It says it even in Binghamton University, University at Albany, State University of New York, and Stony Brook University. Stop trying to say it's not because I am totally right in this case.\"\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t\" \n",
            "\n",
            " == Before adding a new product to the list, make sure it's relevant == \n",
            "\n",
            " Before adding a new product to the list, make sure it has a wikipedia entry already, \"\"proving\"\" it's relevance and giving the reader the possibility to read more about it. \n",
            " Otherwise it could be subject to deletion. See this article's revision history.\"\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\t==Current Position== \n",
            " Anyone have confirmation that Sir, Alfred is no longer at the airport and is hospitalised?\n",
            "\n",
            "[Predicted]: \n",
            "\t {'toxic': False, 'severe_toxic': False, 'obscene': False, 'threat': False, 'insult': False, 'identity_hate': False}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnHANrAeZ_F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}