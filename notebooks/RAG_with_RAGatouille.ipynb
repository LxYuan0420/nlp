{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -q ragatouille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic indexing and searching with RAGatouille\n",
    "\n",
    "In this quick example, we'll use the `RAGPretrainedModel` magic class to demonstrate how to:\n",
    "\n",
    "- **Build an index from raw documents**\n",
    "- **Search an index for relevant documents**\n",
    "- **Load an index and the associated pretrained model to update or query it.**\n",
    "\n",
    "Please note: Indexing is currently not supported on Google Colab and Windows 10.\n",
    "\n",
    "First, let's load up a pre-trained ColBERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/likxun/skynet/env30/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "RAG = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's all you need to do to load the model! All the config is now stored, and ready to be used for indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_page(title: str):\n",
    "    \"\"\"\n",
    "    Retrieve the full text content of a Wikipedia page.\n",
    "    \n",
    "    :param title: str - Title of the Wikipedia page.\n",
    "    :return: str - Full text content of the page as raw string.\n",
    "    \"\"\"\n",
    "    # Wikipedia API endpoint\n",
    "    URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "    # Parameters for the API request\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "\n",
    "    # Custom User-Agent header to comply with Wikipedia's best practices\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Wikipedia RAGatouille (Lx Yuan)\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(URL, params=params, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    # Extracting page content\n",
    "    page = next(iter(data['query']['pages'].values()))\n",
    "    return page['extract'] if 'extract' in page else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's use it to fetch the page's content and check how long it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionair\n"
     ]
    }
   ],
   "source": [
    "elon_content = get_wikipedia_page(\"Elon Musk\")\n",
    "print(elon_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of characters! Thankfully, `RAGPretrainedColBERT.index()` also relies on a `CorpusProcessor`! It takes in various pre-processing functions and applies them to your documents before embedding and indexing them.\n",
    "\n",
    "By default, `CorpusProcessor` uses LlamaIndex's `SentenceSplitter`, with a chunk-size defined by your index's max document length. By default, `max_document_length` is 256 tokens, but you can set it to whatever you like.\n",
    "\n",
    "Let's keep our information units small and go for 180 when creating our index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.\n",
      " This means that indexing will be slow. To make use of your GPU.\n",
      "Please install `faiss-gpu` by running:\n",
      "pip uninstall --y faiss-cpu & pip install faiss-gpu\n",
      " ________________________________________________________________________________\n",
      "Will continue with CPU indexing in 5 seconds...\n",
      "\n",
      "\n",
      "[Jan 11, 09:26:22] #> Note: Output directory .ragatouille/colbert/indexes/elon_musk already exists\n",
      "\n",
      "\n",
      "[Jan 11, 09:26:22] #> Will delete 10 files already at .ragatouille/colbert/indexes/elon_musk in 20 seconds...\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "[Jan 11, 09:26:46] [0] \t\t #> Encoding 107 passages..\n",
      "[Jan 11, 09:26:49] [0] \t\t avg_doclen_est = 135.12149047851562 \t len(local_sample) = 107\n",
      "[Jan 11, 09:26:49] [0] \t\t Creating 1,024 partitions.\n",
      "[Jan 11, 09:26:49] [0] \t\t *Estimated* 14,457 embeddings.\n",
      "[Jan 11, 09:26:49] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/elon_musk/plan.json ..\n",
      "Clustering 13736 points in 128D to 1024 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n",
      "  Iteration 1 (0.15 s, search 0.15 s): objective=4027.31 imbalance=1.504 nsplit=0       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 13736 points to 1024 centroids: please provide at least 39936 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 09:26:50] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "\n",
      "[Jan 11, 09:26:50] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.036, 0.04, 0.039, 0.038, 0.037, 0.042, 0.037, 0.037, 0.035, 0.039, 0.033, 0.036, 0.039, 0.04, 0.038, 0.041, 0.033, 0.035, 0.032, 0.036, 0.038, 0.037, 0.037, 0.039, 0.035, 0.036, 0.037, 0.038, 0.039, 0.038, 0.037, 0.045, 0.04, 0.035, 0.038, 0.033, 0.039, 0.037, 0.038, 0.043, 0.038, 0.035, 0.041, 0.041, 0.037, 0.034, 0.037, 0.042, 0.04, 0.038, 0.038, 0.039, 0.04, 0.038, 0.037, 0.037, 0.046, 0.038, 0.039, 0.037, 0.036, 0.041, 0.038, 0.037, 0.039, 0.038, 0.04, 0.04, 0.034, 0.039, 0.04, 0.037, 0.039, 0.038, 0.038, 0.034, 0.038, 0.045, 0.039, 0.04, 0.039, 0.039, 0.037, 0.037, 0.04, 0.037, 0.035, 0.039, 0.034, 0.047, 0.037, 0.04, 0.036, 0.041, 0.036, 0.04, 0.043, 0.034, 0.037, 0.036, 0.042, 0.041, 0.035, 0.036, 0.037, 0.038, 0.04, 0.035, 0.037, 0.036, 0.038, 0.039, 0.041, 0.037, 0.041, 0.035, 0.036, 0.04, 0.04, 0.038, 0.035, 0.039, 0.036, 0.04, 0.035, 0.039, 0.041, 0.035]\n",
      "[Jan 11, 09:26:50] [0] \t\t #> Encoding 107 passages..\n",
      "[Jan 11, 09:26:50] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 09:26:50] #> Building the emb2pid mapping..\n",
      "[Jan 11, 09:26:50] len(emb2pid) = 14458\n",
      "[Jan 11, 09:26:50] #> Saved optimized IVF to .ragatouille/colbert/indexes/elon_musk/ivf.pid.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  6.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1889.33it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 103750.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n",
      "Done indexing!\n"
     ]
    }
   ],
   "source": [
    "RAG.index(\n",
    "    collection=[elon_content], \n",
    "    index_name=\"elon_musk\", \n",
    "    max_document_length=180, \n",
    "    split_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's our index created! It's already compressed and save to disk, so you're ready to use it anywhere you want. By the way, the default behaviour of `index()` is to split documents, but if for any reason you'd like them to remain intact (if you've already preprocessed them, for example), you can set it to false to bypass it!\n",
    "\n",
    "Let's move on to querying our index now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RAGPretrainedModel` has just indexed our document, so the index is already loaded into it and ready to use! \n",
    "\n",
    "Searching is very simple and straightforward, let's say I have a single query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading searcher for index elon_musk for the first time... This may take a few seconds\n",
      "[Jan 11, 09:27:22] #> Loading codec...\n",
      "[Jan 11, 09:27:22] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 09:27:22] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jan 11, 09:27:22] #> Loading IVF...\n",
      "[Jan 11, 09:27:22] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3930.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 09:27:22] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 722.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who is Elon Musk?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2003,  3449,  2239, 14163,  6711,  1029,   102,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103], device='cuda:0')\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation.',\n",
       "  'score': 27.78125,\n",
       "  'rank': 1},\n",
       " {'content': \"; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is the wealthiest person in the world, with an estimated net worth of US$232 billion as of December 2023, according to the Bloomberg Billionaires Index, and $254 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics.\",\n",
       "  'score': 24.421875,\n",
       "  'rank': 2},\n",
       " {'content': \"To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\\n\\n\\n== Early life and education ==\\n\\n\\n=== Childhood and family ===\\n\\nElon Reeve Musk was born on June 28, 1971, in Pretoria, South Africa's administrative capital. He has British and Pennsylvania Dutch ancestry. His mother, Maye Musk (née Haldeman), is a model and dietitian born in Saskatchewan, Canada, and raised in South Africa. His father, Errol Musk, is a South African electromechanical engineer, pilot, sailor, consultant, and property developer, who partly owned a Zambian emerald mine near Lake Tanganyika, as well as a rental lodge at the Timbavati Private Nature Reserve.\",\n",
       "  'score': 23.34375,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3 # How many documents you want to retrieve, defaults to 10, we set it to 3 here for readability\n",
    "results = RAG.search(query=\"Who is Elon Musk?\", k=k)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But is it efficient? Let's check how long it takes ColBERT to embed our query and retrieve documents. Because ColBERT's main retrieval approach relies on `maxsim`, a very efficient operation, searching through orders of magnitudes more documents shouldn't take much longer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 ms ± 93.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "RAG.search(query=\"Who is Elon Musk?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also batch queries, which will run faster if you've got many different queries to run at once. The output format is the same as for a single query, except it's a list of lists, where item at index `i` will correspond to the query at index `i`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 112.43it/s]\n"
     ]
    }
   ],
   "source": [
    "all_results = RAG.search(\n",
    "    query=[\n",
    "        \"What is SpaceX\", \n",
    "        \"What is durian?\" # irrelevant query\n",
    "    ], \n",
    "    k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company.',\n",
       "  'score': 23.59375,\n",
       "  'rank': 1},\n",
       " {'content': 'In 2020, SpaceX launched its first crewed flight, the Demo-2, becoming the first private company to place astronauts into orbit and dock a crewed spacecraft with the ISS.\\n\\n\\n==== Starlink ====\\n\\nIn 2015, SpaceX began development of the Starlink constellation of low-Earth-orbit satellites to provide satellite Internet access, with the first two prototype satellites launched in February 2018. A second set of test satellites, and the first large deployment of a piece of the constellation, occurred in May 2019, when the first 60 operational satellites were launched. The total cost of the decade-long project to design, build, and deploy the constellation is estimated by SpaceX to be about $10 billion.',\n",
       "  'score': 22.625,\n",
       "  'rank': 2},\n",
       " {'content': \"In 2012, the Dragon vehicle docked with the ISS, a first for a commercial spacecraft.\\nWorking towards its goal of reusable rockets, in 2015 SpaceX successfully landed the first stage of a Falcon 9 on an inland platform. Later landings were achieved on autonomous spaceport drone ships, an ocean-based recovery platform. In 2018, SpaceX launched the Falcon Heavy; the inaugural mission carried Musk's personal Tesla Roadster as a dummy payload. Since 2019, SpaceX has been developing Starship, a fully-reusable, super-heavy-lift launch vehicle intended to replace the Falcon 9 and the Falcon Heavy. In 2020, SpaceX launched its first crewed flight, the Demo-2, becoming the first private company to place astronauts into orbit and dock a crewed spacecraft with the ISS.\",\n",
       "  'score': 22.203125,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is SpaceX\n",
    "all_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Time has listed Musk as one of the most influential people in the world on four occasions in 2010, 2013, 2018, and 2021. Musk was selected as Time\\'s \"Person of the Year\" for 2021. Then Time editor-in-chief Edward Felsenthal wrote that \"Person of the Year is a marker of influence, and few individuals have had more influence than Musk on life on Earth, and potentially life off Earth too\". In February 2022, Musk was elected to the National Academy of Engineering. Following a tumultuous year of changes and controversies at X, The New Republic labeled Musk its 2023 Scoundrel of the Year.\\n\\n\\n== Notes and references ==\\n\\n\\n=== Notes ===\\n\\n\\n=== Citations ===\\n\\n\\n== Works cited ==',\n",
       "  'score': 5.74609375,\n",
       "  'rank': 1},\n",
       " {'content': 'Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect and former chairman of Tesla, Inc.; owner, chairman and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation.',\n",
       "  'score': 5.671875,\n",
       "  'rank': 2},\n",
       " {'content': '=== OpenAI and xAI ===\\n\\nIn December 2015, Musk co-founded OpenAI, a not-for-profit artificial intelligence (AI) research company aiming to develop artificial general intelligence intended to be safe and beneficial to humanity. A particular focus of the company is to democratize artificial superintelligence systems, against governments and corporations. Musk pledged $1 billion of funding to OpenAI. In 2023, Musk tweeted that he had ended up giving a total of $100 million to OpenAI. TechCrunch later reported that, according to its own investigation of public records, \"only $15 million\" of OpenAI\\'s funding could be definitively traced to Musk.',\n",
       "  'score': 5.3046875,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is durian?\n",
    "all_results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it for the basics of querying an index! You're now ready to index and retrieve documents with RAGatouille!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an already-created index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples above, we embedded documents into an index and queried it during the same session. But a key feature is **persistence**: indexing is the slowest part, we don't want to have to do this every-time!\n",
    "\n",
    "Loading an already-created Index is just as straightforward as creating one from scratch. First, we'll load up an instance of RAGPretrainedModel from the index, where the full configuration of the embedder is stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is the path to index. We recommend keeping this path format when using RAGatouille somewhere else.\n",
    "path_to_index = \".ragatouille/colbert/indexes/elon_musk/\"\n",
    "RAG = RAGPretrainedModel.from_index(path_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'At the same time, Musk refused to block Russian state media on Starlink, declaring himself \"a free speech absolutist\".\\n\\n\\n=== Tesla ===\\n\\nTesla, Inc., originally Tesla Motors, was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning, who financed the company until the Series A round of funding. Both men played active roles in the company\\'s early development prior to Musk\\'s involvement. Musk led the Series A round of investment in February 2004; he invested $6.5 million, became the majority shareholder, and joined Tesla\\'s board of directors as chairman.',\n",
       "  'score': 21.03125,\n",
       "  'rank': 1},\n",
       " {'content': 'As of 2019, Musk was the longest-tenured CEO of any automotive manufacturer globally. In 2021, Musk nominally changed his title to \"Technoking\" while retaining his position as CEO.\\nTesla began delivery of an electric sports car, the Roadster, in 2008. With sales of about 2,500 vehicles, it was the first serial production all-electric car to use lithium-ion battery cells. Tesla began delivery of its four-door Model S sedan in 2012. A cross-over, the Model X was launched in 2015. A mass-market sedan, the Model 3, was released in 2017. The Model 3 is the all-time bestselling plug-in electric car worldwide, and in June 2021 it became the first electric car to sell 1 million units globally.',\n",
       "  'score': 19.78125,\n",
       "  'rank': 2},\n",
       " {'content': 'The Model 3 is the all-time bestselling plug-in electric car worldwide, and in June 2021 it became the first electric car to sell 1 million units globally. A fifth vehicle, the Model Y crossover, was launched in 2020. The Cybertruck, an all-electric pickup truck, was unveiled in 2019. Under Musk, Tesla has also constructed multiple lithium-ion battery and electric vehicle factories, named Gigafactories.Since its initial public offering in 2010, Tesla stock has risen significantly; it became the most valuable carmaker in summer 2020, and it entered the S&P 500 later that year. In October 2021, it reached a market capitalization of $1 trillion, the sixth company in U.S. history to do so.',\n",
       "  'score': 19.578125,\n",
       "  'rank': 3}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3 # How many documents you want to retrieve, defaults to 10, we set it to 3 here for readability\n",
    "results = RAG.search(query=\"Tesla is ...?\", k=k)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! The index is now fully ready to be queried using `search()` as above.\n",
    "\n",
    "### Updating an index\n",
    "\n",
    "Once you've loaded an existing index, you might want to add new documents to it. RAGatouille supports this via the `RAGPretrainedModel.add_to_index()` function. Due to the way ColBERT stores documents as bags-of-embeddings, there are cases where recreating the index is more efficient than updating it -- you don't need to worry about it, the most efficient method is automatically used when you call `add_to_index()`.\n",
    "\n",
    "You want to expand, and cover more of Studio Ghibli, so let's get the Studio's page into our index too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: add_to_index support is currently experimental! add_to_index support will be more thorough in future versions\n",
      "[Jan 11, 09:31:33] #> Loading codec...\n",
      "[Jan 11, 09:31:33] #> Loading IVF...\n",
      "[Jan 11, 09:31:33] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2571.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 09:31:33] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 764.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.\n",
      " This means that indexing will be slow. To make use of your GPU.\n",
      "Please install `faiss-gpu` by running:\n",
      "pip uninstall --y faiss-cpu & pip install faiss-gpu\n",
      " ________________________________________________________________________________\n",
      "Will continue with CPU indexing in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New index_name received! Updating current index_name (elon_musk) to elon_musk\n",
      "\n",
      "\n",
      "[Jan 11, 09:31:38] #> Note: Output directory .ragatouille/colbert/indexes/elon_musk already exists\n",
      "\n",
      "\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "[Jan 11, 09:31:43] [0] \t\t #> Encoding 285 passages..\n",
      "[Jan 11, 09:31:45] [0] \t\t avg_doclen_est = 131.62806701660156 \t len(local_sample) = 285\n",
      "[Jan 11, 09:31:45] [0] \t\t Creating 2,048 partitions.\n",
      "[Jan 11, 09:31:45] [0] \t\t *Estimated* 37,513 embeddings.\n",
      "[Jan 11, 09:31:45] [0] \t\t #> Saving the indexing plan to .ragatouille/colbert/indexes/elon_musk/plan.json ..\n",
      "Clustering 35639 points in 128D to 2048 clusters, redo 1 times, 20 iterations\n",
      "  Preprocessing in 0.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 35639 points to 2048 centroids: please provide at least 79872 training points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 09:31:52] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "\n",
      "[Jan 11, 09:31:52] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[0.037, 0.043, 0.04, 0.038, 0.037, 0.041, 0.035, 0.036, 0.035, 0.037, 0.037, 0.036, 0.037, 0.039, 0.038, 0.038, 0.032, 0.035, 0.034, 0.037, 0.038, 0.037, 0.039, 0.04, 0.034, 0.036, 0.039, 0.039, 0.039, 0.038, 0.035, 0.041, 0.041, 0.037, 0.037, 0.033, 0.041, 0.038, 0.039, 0.046, 0.039, 0.035, 0.041, 0.039, 0.036, 0.035, 0.038, 0.041, 0.041, 0.036, 0.038, 0.038, 0.037, 0.038, 0.04, 0.04, 0.044, 0.04, 0.045, 0.036, 0.035, 0.039, 0.038, 0.04, 0.041, 0.039, 0.039, 0.041, 0.036, 0.038, 0.04, 0.036, 0.037, 0.04, 0.037, 0.037, 0.038, 0.043, 0.041, 0.039, 0.039, 0.04, 0.037, 0.038, 0.04, 0.037, 0.036, 0.038, 0.036, 0.042, 0.037, 0.038, 0.037, 0.039, 0.036, 0.039, 0.042, 0.036, 0.037, 0.037, 0.04, 0.042, 0.035, 0.035, 0.038, 0.038, 0.038, 0.036, 0.04, 0.034, 0.035, 0.038, 0.04, 0.037, 0.04, 0.039, 0.035, 0.04, 0.039, 0.038, 0.036, 0.039, 0.036, 0.041, 0.036, 0.037, 0.038, 0.035]\n",
      "[Jan 11, 09:31:52] [0] \t\t #> Encoding 285 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1707.78it/s]\n",
      "100%|██████████| 2048/2048 [00:00<00:00, 109872.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jan 11, 09:31:52] #> Optimizing IVF to store map from centroids to list of pids..\n",
      "[Jan 11, 09:31:52] #> Building the emb2pid mapping..\n",
      "[Jan 11, 09:31:52] len(emb2pid) = 37514\n",
      "[Jan 11, 09:31:52] #> Saved optimized IVF to .ragatouille/colbert/indexes/elon_musk/ivf.pid.pt\n",
      "#> Joined...\n",
      "Done indexing!\n",
      "Successfully updated index with 178 new documents!\n",
      " New index size: 285\n"
     ]
    }
   ],
   "source": [
    "new_documents = get_wikipedia_page(\"Donald Trump\")\n",
    "\n",
    "RAG.add_to_index([new_documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, that's it! The index has been updated with your new document set, and the updates are already persisted to disk. You're now ready to query it with `search()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mMiyazaki\u001b[0m/  \u001b[01;34melon_musk\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls .ragatouille/colbert/indexes/"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
