{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/nlp/blob/main/notebooks/Semantic_deduplication_using_model2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kysu86bu9VId"
      },
      "source": [
        "**Semantic Deduplication with Model2Vec**\n",
        "\n",
        "In this tutorial, we’ll explore how Model2Vec can help identify duplicates in text data that traditional exact matching would miss. While exact matching works for identical texts, it fails to detect near-duplicates—documents that may differ slightly in wording but convey the same meaning. Using Model2Vec, we embed documents into vectors and measure their similarity. This allows us to catch both exact and semantic duplicates, improving the quality of our dataset. With Model2Vec’s speed and efficiency, we can very efficiently perform deduplication on large datasets, ensuring cleaner, more robust data for downstream tasks. Additionally, we will use Model2Vec to detect train-test overlap, ensuring our models are not overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "128dqt6g9VIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "f2cc3489a6c8473f98da7c05235f3ffb",
            "ed080749943344cfae8043b2976cbfc8",
            "bdf124422b114c329774f5916d60eb37",
            "907bd66819304c91837c3de7941855aa",
            "e9d01112ce0a4660987bccb1bbfa8298",
            "368ccf1f72e24a1d9f35f893620edab3",
            "3aa9ec953d1b4c53ab89d7e440976f07",
            "0b5503ae42904f5fb04bfbb22276cef0",
            "7e5daf2ca4e640eab9989ad6bc63770f",
            "5a042665ca4f48978b351c01c31699cb",
            "bacdd9b53f37445c97bd41960607272a"
          ]
        },
        "outputId": "affdbe7a-a115-41e5-e269-af72cba17b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2cc3489a6c8473f98da7c05235f3ffb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install datasets model2vec reach numpy wordllama tqdm datasketch\n",
        "!pip install -U sentence-transformers\n",
        "\n",
        "from difflib import ndiff\n",
        "from time import perf_counter\n",
        "\n",
        "from datasets import load_dataset\n",
        "from datasketch import MinHash, MinHashLSH\n",
        "import numpy as np\n",
        "from model2vec import StaticModel\n",
        "from reach import Reach\n",
        "from tqdm import tqdm\n",
        "from wordllama import WordLlama\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUKbzc2y9VIj"
      },
      "source": [
        "**Loading data and model**\n",
        "\n",
        "We will use the AG News dataset and the Model2Vec pretrained model for deduplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RbPa35Q9VIk"
      },
      "outputs": [],
      "source": [
        "# Load the model and dataset\n",
        "model = SentenceTransformer(\"Thaweewat/gte-multilingual-base-m2v-256\")\n",
        "#model = StaticModel.from_pretrained(\"Thaweewat/gte-multilingual-base-m2v-256\", folder=\"0_StaticEmbedding\")\n",
        "ds = load_dataset(\"PolyAI/banking77\")[\"train\"]\n",
        "texts = ds['text']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before deduplication: {len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E0YL_aiAmhq",
        "outputId": "286540cd-b797-45d8-bca6-af3e1777632e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before deduplication: 10003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyfRRFtp9VIk"
      },
      "source": [
        "**Exact overlap baseline**\n",
        "\n",
        "We will first try to find exact matches in the dataset as a baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5uGvLGZ_9VIk",
        "outputId": "e742ac4c-0b7c-4308-9b60-08268c77d8f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deduplicated docs: 10003\n"
          ]
        }
      ],
      "source": [
        "seen = set()\n",
        "deduplicated_text_indices = []\n",
        "\n",
        "for i, text in enumerate(texts):\n",
        "    if text not in seen:\n",
        "        deduplicated_text_indices.append(i)\n",
        "        seen.add(text)\n",
        "\n",
        "print(\"Number of deduplicated docs:\", len(deduplicated_text_indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_XjAlJI9VIl"
      },
      "source": [
        "As can be seen, we find no duplicate instances using exact string matching.\n",
        "\n",
        "**Deduplication using Model2Vec**\n",
        "\n",
        "Let's now use Model2Vec to embed our documents and identify duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gTRqv20q9VIm"
      },
      "outputs": [],
      "source": [
        "# Encode texts into embeddings\n",
        "embedding_matrix = model.encode(texts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOdb0qM7BnbX",
        "outputId": "846c5864-0771-403c-b5ea-186e8a5b692d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10003, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HTrHt7wx9VIm"
      },
      "outputs": [],
      "source": [
        "def deduplicate(embedding_matrix: np.ndarray, threshold: float, batch_size: int = 1024) -> tuple[np.ndarray, dict[int, int]]:\n",
        "    \"\"\"\n",
        "    Deduplicate embeddings and return the deduplicated indices and a mapping of removed indices to their corresponding original indices.\n",
        "\n",
        "    :param embedding_matrix: The embeddings to deduplicate.\n",
        "    :param threshold: The similarity threshold to use for deduplication.\n",
        "    :param batch_size: The batch size to use for similarity computation.\n",
        "    :return: A tuple containing the deduplicated indices and a dictionary mapping removed indices to original indices.\n",
        "    \"\"\"\n",
        "    reach = Reach(vectors=embedding_matrix, items=[str(i) for i in range(len(embedding_matrix))])\n",
        "\n",
        "    # Use a set for deduplicated indices and keep track of duplicates\n",
        "    deduplicated_indices = set(range(len(embedding_matrix)))  # Start with all indices as deduplicated\n",
        "    duplicate_to_original_mapping = {}\n",
        "\n",
        "    results = reach.nearest_neighbor_threshold(\n",
        "        embedding_matrix,\n",
        "        threshold=threshold,\n",
        "        batch_size=batch_size,\n",
        "        show_progressbar=True\n",
        "    )\n",
        "\n",
        "    # Process duplicates\n",
        "    for i, similar_items in enumerate(tqdm(results)):\n",
        "        if i not in deduplicated_indices:\n",
        "            continue  # Skip already marked duplicates\n",
        "\n",
        "        # Similar items are returned as (index, score), we are only interested in the index\n",
        "        similar_indices = [int(item[0]) for item in similar_items if int(item[0]) != i]\n",
        "\n",
        "        # Mark similar documents as duplicates and map them to the original\n",
        "        for sim_idx in similar_indices:\n",
        "            if sim_idx in deduplicated_indices:\n",
        "                deduplicated_indices.remove(sim_idx)\n",
        "                duplicate_to_original_mapping[sim_idx] = i  # Map duplicate to original\n",
        "\n",
        "    return np.array(list(deduplicated_indices)), duplicate_to_original_mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hLw4Pwml9VIn",
        "outputId": "735c4acd-cd64-4161-9962-300ff16cbb9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  7.65it/s]\n",
            "100%|██████████| 10003/10003 [00:00<00:00, 588215.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deduplicated docs: 9913\n",
            "Time taken: 1.3645381600001656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Deduplicate (with a high threshold)\n",
        "time = perf_counter()\n",
        "deduplicated_indices, duplicate_to_original_mapping = deduplicate(embedding_matrix, threshold=0.99)\n",
        "print(f\"Number of deduplicated docs: {len(deduplicated_indices)}\")\n",
        "print(f\"Time taken: {perf_counter() - time}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "10003 - 9913"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrOY69z0BFd0",
        "outputId": "b1d5b80c-82ac-4b9a-c0cb-895d5af2cd4b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKATTxLg9VIn"
      },
      "source": [
        "Using Model2Vec, we find about 90 duplicates with a very high threshold, in < 3 seconds. Now, let's look at a few examples to see if these are indeed duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SCXdv4Il9VIn",
        "outputId": "218364f6-6090-4ea7-c9d2-7a03981193e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Original text]:\n",
            "How do I track the card you sent me?\n",
            "\n",
            "[Duplicate text]:\n",
            "How do I track the card you sent to me?\n",
            "\n",
            "[Differences]:\n",
            "+ to\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "from where are coming your exchange rates?\n",
            "\n",
            "[Duplicate text]:\n",
            "Your exchange rates are coming from where?\n",
            "\n",
            "[Differences]:\n",
            "- from - where + Your + exchange + rates + from + where? - your - exchange - rates?\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "The exchange rate you are using is bad.This can't be the official interbank exchange rate.\n",
            "\n",
            "[Duplicate text]:\n",
            "The exchange rate you are using is really bad.This can't be the official interbank exchange rate.\n",
            "\n",
            "[Differences]:\n",
            "+ really\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "I got a €1 extra fee in my statement\n",
            "\n",
            "[Duplicate text]:\n",
            "In my statement, I got a €1 extra fee.\n",
            "\n",
            "[Differences]:\n",
            "+ In + my + statement, - fee + fee. - in - my - statement\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "There is an extra 1£ charge on my app. Why did you charge me extra?\n",
            "\n",
            "[Duplicate text]:\n",
            "There is  an extra 1£ charge on my app. Why did it charge me extra?\n",
            "\n",
            "[Differences]:\n",
            "- you + it\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "What does pending mean on a cash withdrawal?\n",
            "\n",
            "[Duplicate text]:\n",
            "What does a pending cash withdrawal mean?\n",
            "\n",
            "[Differences]:\n",
            "+ a - mean - on - a - withdrawal? + withdrawal + mean?\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "To deliver to the US, how long will it take?\n",
            "\n",
            "[Duplicate text]:\n",
            "How long will it take to deliver to the US?\n",
            "\n",
            "[Differences]:\n",
            "- To + How + long + will + it + take + to + US? - US, - how - long - will - it - take?\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "How long is a delivery to the US?\n",
            "\n",
            "[Duplicate text]:\n",
            "How long is delivery to the US?\n",
            "\n",
            "[Differences]:\n",
            "- a\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "How long is a delivery to the US?\n",
            "\n",
            "[Duplicate text]:\n",
            "How long is the delivery to the US?\n",
            "\n",
            "[Differences]:\n",
            "- a + the\n",
            "--------------------------------------------------\n",
            "\n",
            "[Original text]:\n",
            "I can't seem to be able to use my card\n",
            "\n",
            "[Duplicate text]:\n",
            "\n",
            "I can't seem to be able to use my card\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "[Differences]:\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def display_word_differences(x: str, y: str) -> str:\n",
        "    diff = ndiff(x.split(), y.split())\n",
        "    return \" \".join([f\"{word}\" for word in diff if word.startswith(('+', '-'))])\n",
        "\n",
        "# Show a few duplicates with their originals, highlighting word-level differences\n",
        "num_examples = 10\n",
        "for duplicate_idx, original_idx in list(duplicate_to_original_mapping.items())[:num_examples]:\n",
        "    print(f\"\\n[Original text]:\\n{texts[original_idx]}\")\n",
        "    print(f\"\\n[Duplicate text]:\\n{texts[duplicate_idx]}\")\n",
        "    print(\"\\n[Differences]:\")\n",
        "    print(display_word_differences(texts[original_idx], texts[duplicate_idx]))\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBk3KESl9VIo"
      },
      "source": [
        "The found texts do indeed seem to be duplicates, nice! In a normal workflow where we use Model2Vec to embed our documents, deduplication our training corpus is essentially free. This gives us an easy to use, easy to integrate, fast way to deduplicate.\n",
        "\n",
        "**Deduplication using WordLlama**\n",
        "\n",
        "For comparison, let's also try a different library (WordLlama), which also uses static embeddings to deduplicate text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ovAwKnLc9VIo",
        "outputId": "3dfa524d-7dc9-4f4d-c1f1-f6e62a4e9456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deduplicated docs: 9900\n",
            "Time taken: 2.520501794999973\n"
          ]
        }
      ],
      "source": [
        "wl = WordLlama.load()\n",
        "\n",
        "time = perf_counter()\n",
        "deduplicated_docs = wl.deduplicate(texts, threshold=0.99)\n",
        "print(f\"Number of deduplicated docs: {len(deduplicated_docs)}\")\n",
        "print(f\"Time taken: {perf_counter() - time}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV76QfJ69VIo"
      },
      "source": [
        "This approach is considerably slower than Model2Vec for encoding + deduplication (1.3 vs 2.5 seconds). It also finds less duplicates with the same threshold.\n",
        "\n",
        "**Deduplication using MinHash**\n",
        "\n",
        "As a last comparison, let's use MinHash, a common method for deduplication. We will use the datasketch library to find duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rL479ECS9VIo",
        "outputId": "aa06be9d-0e8f-4f36-8e00-535ae8565408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deduplicated docs: 9957\n",
            "Time taken: 18.21741431999999\n"
          ]
        }
      ],
      "source": [
        "def get_minhash(text: str, num_perm: int = 128) -> MinHash:\n",
        "    m = MinHash(num_perm=num_perm)\n",
        "    for word in text.split():\n",
        "        m.update(word.encode('utf8'))\n",
        "    return m\n",
        "\n",
        "def deduplicate_with_minhash(texts: list[str], threshold: float = 0.9) -> list[int]:\n",
        "    \"\"\"\n",
        "    Deduplicate texts using MinHash and return the indices of unique texts.\n",
        "\n",
        "    :param texts: List of texts to deduplicate.\n",
        "    :param threshold: Jaccard similarity threshold for considering texts as duplicates.\n",
        "    :return: List of indices of deduplicated texts.\n",
        "    \"\"\"\n",
        "    lsh = MinHashLSH(threshold=threshold)\n",
        "    deduplicated_text_indices = []\n",
        "\n",
        "    for i, text in enumerate(texts):\n",
        "        # Generate MinHash for the current text\n",
        "        minhash = get_minhash(text)\n",
        "\n",
        "        # Check if the MinHash is already in the LSH (i.e., if it is a duplicate)\n",
        "        if not lsh.query(minhash):\n",
        "            # If it's not a duplicate, add the MinHash and keep the index\n",
        "            deduplicated_text_indices.append(i)\n",
        "            lsh.insert(i, minhash)\n",
        "\n",
        "    return deduplicated_text_indices\n",
        "\n",
        "\n",
        "time = perf_counter()\n",
        "deduplicated_text_indices = deduplicate_with_minhash(texts)\n",
        "print(f\"Number of deduplicated docs: {len(deduplicated_text_indices)}\")\n",
        "print(f\"Time taken: {perf_counter() - time}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Br4TN49VIp"
      },
      "source": [
        "Model2Vec is again much faster, with 1.3 seconds vs 18 seconds for MinHash. The number of found duplicates is roughly the same using the default settings for MinHash.\n",
        "\n",
        "-----\n",
        "\n",
        "**Train test leakage detection using Model2Vec**\n",
        "\n",
        "Now, as a last experiment, let's also embed the test set, and see if there are any duplicates between the training and test set. This is a common issue in NLP, where the test set may contain instances that are also in the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vI4BAxdD9VIp",
        "outputId": "727a9b09-3feb-42b0-c5e0-889ae480610e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00,  9.36it/s]\n",
            "100%|██████████| 3080/3080 [00:00<00:00, 644119.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicates found between train and test: 61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "ds_train = load_dataset(\"PolyAI/banking77\")[\"train\"]\n",
        "ds_test = load_dataset(\"PolyAI/banking77\")[\"test\"]\n",
        "\n",
        "texts_train = ds_train['text']\n",
        "texts_test = ds_test['text']\n",
        "\n",
        "# Encode texts into embeddings\n",
        "embedding_matrix_train = model.encode(texts_train)\n",
        "embedding_matrix_test = model.encode(texts_test)\n",
        "\n",
        "def deduplicate_across_datasets(embedding_matrix_1: np.ndarray, embedding_matrix_2: np.ndarray, threshold: float, batch_size: int = 1024) -> tuple[list[int], dict[int, int]]:\n",
        "    \"\"\"\n",
        "    Deduplicate embeddings across two datasets and return the indices of duplicates between them.\n",
        "\n",
        "    :param embedding_matrix_1: The embeddings of the first dataset (e.g., train).\n",
        "    :param embedding_matrix_2: The embeddings of the second dataset (e.g., test).\n",
        "    :param threshold: The similarity threshold to use for deduplication.\n",
        "    :param batch_size: The batch size to use for similarity computation.\n",
        "    :return: A tuple containing the duplicate indices and a dictionary mapping removed indices in the second dataset to their corresponding indices in the first dataset.\n",
        "    \"\"\"\n",
        "    reach = Reach(vectors=embedding_matrix_1, items=[str(i) for i in range(len(embedding_matrix_1))])\n",
        "\n",
        "    # Keep track of duplicates in the second dataset\n",
        "    duplicate_indices_in_test = []\n",
        "    duplicate_to_original_mapping = {}\n",
        "\n",
        "    # Find nearest neighbors from the test set in the train set\n",
        "    results = reach.nearest_neighbor_threshold(\n",
        "        embedding_matrix_2,\n",
        "        threshold=threshold,\n",
        "        batch_size=batch_size,\n",
        "        show_progressbar=True\n",
        "    )\n",
        "\n",
        "    # Process duplicates\n",
        "    for i, similar_items in enumerate(tqdm(results)):\n",
        "        # Similar items are returned as (index, score), we are only interested in the index\n",
        "        similar_indices = [int(item[0]) for item in similar_items if item[1] >= threshold]  # Keep those above the threshold\n",
        "\n",
        "        # If we find a similar item in the train set, mark it as a duplicate\n",
        "        if similar_indices:\n",
        "            duplicate_indices_in_test.append(i)\n",
        "            duplicate_to_original_mapping[i] = similar_indices[0]  # Map duplicate in test to original in train\n",
        "\n",
        "    return duplicate_indices_in_test, duplicate_to_original_mapping\n",
        "\n",
        "# Check for train/test bleed\n",
        "duplicate_indices_in_test, duplicate_to_original_mapping = deduplicate_across_datasets(\n",
        "    embedding_matrix_train,\n",
        "    embedding_matrix_test,\n",
        "    threshold=0.99  # High threshold for deduplication\n",
        ")\n",
        "\n",
        "print(f\"Number of duplicates found between train and test: {len(duplicate_indices_in_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "toz9JUXN9VIp",
        "outputId": "53a7ca25-90fc-4a34-ee40-515a9588ac20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Train text]:\n",
            "How do I add a card on to the app?\n",
            "\n",
            "[Test text]:\n",
            "How do I add a card to the app?\n",
            "\n",
            "[Differences]:\n",
            "- on\n",
            "--------------------------------------------------\n",
            "\n",
            "[Train text]:\n",
            "I got a €1 extra fee in my statement\n",
            "\n",
            "[Test text]:\n",
            "I got a extra €1 fee in my statement\n",
            "\n",
            "[Differences]:\n",
            "+ extra - extra\n",
            "--------------------------------------------------\n",
            "\n",
            "[Train text]:\n",
            "I tried to get some money but the machine was not working .The transaction still seems in progress! Can you please check what's going on.I don't want to be charged for money that I did not received.\n",
            "\n",
            "[Test text]:\n",
            "Hi,I tried to get some money out but the machine was not working .The transaction still seems in progress! Can you please check what's going on.I don't want to be charged for money that I did not received.\n",
            "\n",
            "[Differences]:\n",
            "- I + Hi,I + out\n",
            "--------------------------------------------------\n",
            "\n",
            "[Train text]:\n",
            "I got cash from an ATM earlier but it shows up as pending in the app. How can this still be pending, I already received the cash?\n",
            "\n",
            "[Test text]:\n",
            "I received cash from the ATM earlier, but this shows up as pending in the app.  I've got the cash already.  How can this be still pending?\n",
            "\n",
            "[Differences]:\n",
            "- got + received - an + the - earlier + earlier, - it + this + I've + got + the + cash + already. + be - be - pending, + pending? - I - already - received - the - cash?\n",
            "--------------------------------------------------\n",
            "\n",
            "[Train text]:\n",
            "Is there a auto top-up option?\n",
            "\n",
            "[Test text]:\n",
            "Is there an auto top-up option?\n",
            "\n",
            "[Differences]:\n",
            "- a + an\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Show a few duplicates with their originals, highlighting word-level differences\n",
        "num_examples = 5\n",
        "for i, test_idx in enumerate(duplicate_indices_in_test[:num_examples]):\n",
        "    train_idx = duplicate_to_original_mapping[test_idx]\n",
        "\n",
        "    print(f\"\\n[Train text]:\\n{texts_train[train_idx]}\")\n",
        "    print(f\"\\n[Test text]:\\n{texts_test[test_idx]}\")\n",
        "    print(\"\\n[Differences]:\")\n",
        "    print(display_word_differences(texts_train[train_idx], texts_test[test_idx]))\n",
        "    print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0SaFOc79VIp"
      },
      "source": [
        "These again look like duplicates. We can very efficiently find train/test leakage examples using Model2Vec, ensuring that our test set is clean and does not contain any duplicates from the training set.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Model2Vec provides an efficient and fast solution for semantic deduplication, outperforming other methods like WordLlama and MinHash in terms of speed. Additionally, its ability to detect train-test overlap makes it a valuable tool for preparing clean datasets for machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit:\n",
        "\n",
        "All credit for this notebook goes to minishlab (https://huggingface.co/minishlab) as it originated from their repository. I have made two primary modifications for experimentation purposes:\n",
        "- [Thaweewat/gte-multilingual-base-m2v-256 model](https://huggingface.co/Thaweewat/gte-multilingual-base-m2v-256) and\n",
        "- [PolyAI/banking77 dataset](https://huggingface.co/datasets/PolyAI/banking77).\n"
      ],
      "metadata": {
        "id": "xJXz2KYcEMn6"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2cc3489a6c8473f98da7c05235f3ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed080749943344cfae8043b2976cbfc8",
              "IPY_MODEL_bdf124422b114c329774f5916d60eb37",
              "IPY_MODEL_907bd66819304c91837c3de7941855aa"
            ],
            "layout": "IPY_MODEL_e9d01112ce0a4660987bccb1bbfa8298"
          }
        },
        "ed080749943344cfae8043b2976cbfc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_368ccf1f72e24a1d9f35f893620edab3",
            "placeholder": "​",
            "style": "IPY_MODEL_3aa9ec953d1b4c53ab89d7e440976f07",
            "value": ""
          }
        },
        "bdf124422b114c329774f5916d60eb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b5503ae42904f5fb04bfbb22276cef0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e5daf2ca4e640eab9989ad6bc63770f",
            "value": 0
          }
        },
        "907bd66819304c91837c3de7941855aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a042665ca4f48978b351c01c31699cb",
            "placeholder": "​",
            "style": "IPY_MODEL_bacdd9b53f37445c97bd41960607272a",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "e9d01112ce0a4660987bccb1bbfa8298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368ccf1f72e24a1d9f35f893620edab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa9ec953d1b4c53ab89d7e440976f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b5503ae42904f5fb04bfbb22276cef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7e5daf2ca4e640eab9989ad6bc63770f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a042665ca4f48978b351c01c31699cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacdd9b53f37445c97bd41960607272a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}