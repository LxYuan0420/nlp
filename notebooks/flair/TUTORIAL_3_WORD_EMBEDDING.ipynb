{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKdzhIWojRVhOuQkSXB9yS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/nlp/blob/main/notebooks/flair/TUTORIAL_3_WORD_EMBEDDING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El7Ot_E72TKw"
      },
      "outputs": [],
      "source": [
        "#!pip install flair"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tutorial 3: Word Embeddings\n",
        "We provide a set of classes with which you can embed the words in sentences in various ways. This tutorial explains how that works. We assume that you're familiar with the base types of this library.\n",
        "\n",
        "###### Embeddings\n",
        "All word embedding classes inherit from the TokenEmbeddings class and implement the embed() method which you need to call to embed your text. This means that for most users of Flair, the complexity of different embeddings remains hidden behind this interface. Simply instantiate the embedding class you require and call embed() to embed your text. All embeddings produced with our methods are PyTorch vectors, so they can be immediately used for training and fine-tuning.\n",
        "\n",
        "This tutorial introduces some common embeddings and shows you how to use them. For more details on these embeddings and an overview of all supported embeddings, check here.\n",
        "\n",
        "###### Classic Word Embeddings\n",
        "\n",
        "Classic word embeddings are static and word-level, meaning that each distinct word gets exactly one pre-computed embedding. Most embeddings fall under this class, including the popular GloVe or Komninos embeddings.\n",
        "\n",
        "Simply instantiate the WordEmbeddings class and pass a string identifier of the embedding you wish to load. So, if you want to use GloVe embeddings, pass the string 'glove' to the constructor:"
      ],
      "metadata": {
        "id": "14LqVkdm4svS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "# init embedding\n",
        "glove_embedding = WordEmbeddings(\"glove\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQ2iMQrp3GZY",
        "outputId": "bbcc75d2-287f-4f94-c31e-9d10f05a8096"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:21:48,977 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpy179fc8e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160000128/160000128 [00:10<00:00, 15844361.35B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:21:59,521 copying /tmp/tmpy179fc8e to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:21:59,819 removing temp file /tmp/tmpy179fc8e\n",
            "2022-11-13 07:22:00,257 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmp2me7d8za\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 11359994.50B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:22:02,549 copying /tmp/tmp2me7d8za to cache at /root/.flair/embeddings/glove.gensim\n",
            "2022-11-13 07:22:02,591 removing temp file /tmp/tmp2me7d8za\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, create an example sentence and call the embedding's embed() method. You can also pass a list of sentences to this method since some embedding types make use of batching to increase speed."
      ],
      "metadata": {
        "id": "gwCvdUps43Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = Sentence(\"The grass is green.\")\n",
        "\n",
        "glove_embedding.embed(sentence)\n",
        "\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)\n",
        "    print(token.embedding.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI2BlJl33Q_o",
        "outputId": "5e5d15b4-0d4a-486c-cf5f-4dc9173a11e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
            "        -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
            "         0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
            "         0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
            "         0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
            "        -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
            "        -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
            "         0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
            "         1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
            "        -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
            "         0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
            "         0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
            "        -0.5203, -0.1459,  0.8278,  0.2706])\n",
            "torch.Size([100])\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.8135,  0.9404, -0.2405, -0.1350,  0.0557,  0.3363,  0.0802, -0.1015,\n",
            "        -0.5478, -0.3537,  0.0734,  0.2587,  0.1987, -0.1433,  0.2507,  0.4281,\n",
            "         0.1950,  0.5346,  0.7424,  0.0578, -0.3178,  0.9436,  0.8145, -0.0824,\n",
            "         0.6166,  0.7284, -0.3262, -1.3641,  0.1232,  0.5373, -0.5123,  0.0246,\n",
            "         1.0822, -0.2296,  0.6039,  0.5541, -0.9610,  0.4803,  0.0022,  0.5591,\n",
            "        -0.1637, -0.8468,  0.0741, -0.6216,  0.0260, -0.5162, -0.0525, -0.1418,\n",
            "        -0.0161, -0.4972, -0.5534, -0.4037,  0.5096,  1.0276, -0.0840, -1.1179,\n",
            "         0.3226,  0.4928,  0.9488,  0.2040,  0.5388,  0.8397, -0.0689,  0.3136,\n",
            "         1.0450, -0.2267, -0.0896, -0.6427,  0.6443, -1.1001, -0.0096,  0.2668,\n",
            "        -0.3230, -0.6065,  0.0479, -0.1664,  0.8571,  0.2335,  0.2539,  1.2546,\n",
            "         0.5472, -0.1980, -0.7186,  0.2076, -0.2587, -0.3650,  0.0834,  0.6932,\n",
            "         0.1574,  1.0931,  0.0913, -1.3773, -0.2717,  0.7071,  0.1872, -0.3307,\n",
            "        -0.2836,  0.1030,  1.2228,  0.8374])\n",
            "torch.Size([100])\n",
            "Token[2]: \"is\"\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635])\n",
            "torch.Size([100])\n",
            "Token[3]: \"green\"\n",
            "tensor([-6.7907e-01,  3.4908e-01, -2.3984e-01, -9.9652e-01,  7.3782e-01,\n",
            "        -6.5911e-04,  2.8010e-01,  1.7287e-02, -3.6063e-01,  3.6955e-02,\n",
            "        -4.0395e-01,  2.4092e-02,  2.8958e-01,  4.0497e-01,  6.9992e-01,\n",
            "         2.5269e-01,  8.0350e-01,  4.9370e-02,  1.5562e-01, -6.3286e-03,\n",
            "        -2.9414e-01,  1.4728e-01,  1.8977e-01, -5.1791e-01,  3.6986e-01,\n",
            "         7.4582e-01,  8.2689e-02, -7.2601e-01, -4.0939e-01, -9.7822e-02,\n",
            "        -1.4096e-01,  7.1121e-01,  6.1933e-01, -2.5014e-01,  4.2250e-01,\n",
            "         4.8458e-01, -5.1915e-01,  7.7125e-01,  3.6685e-01,  4.9652e-01,\n",
            "        -4.1298e-02, -1.4683e+00,  2.0038e-01,  1.8591e-01,  4.9860e-02,\n",
            "        -1.7523e-01, -3.5528e-01,  9.4153e-01, -1.1898e-01, -5.1903e-01,\n",
            "        -1.1887e-02, -3.9186e-01, -1.7479e-01,  9.3451e-01, -5.8931e-01,\n",
            "        -2.7701e+00,  3.4522e-01,  8.6533e-01,  1.0808e+00, -1.0291e-01,\n",
            "        -9.1220e-02,  5.5092e-01, -3.9473e-01,  5.3676e-01,  1.0383e+00,\n",
            "        -4.0658e-01,  2.4590e-01, -2.6797e-01, -2.6036e-01, -1.4151e-01,\n",
            "        -1.2022e-01,  1.6234e-01, -7.4320e-01, -6.4728e-01,  4.7133e-02,\n",
            "         5.1642e-01,  1.9898e-01,  2.3919e-01,  1.2550e-01,  2.2471e-01,\n",
            "         8.2613e-01,  7.8328e-02, -5.7020e-01,  2.3934e-02, -1.5410e-01,\n",
            "        -2.5739e-01,  4.1262e-01, -4.6967e-01,  8.7914e-01,  7.2629e-01,\n",
            "         5.3862e-02, -1.1575e+00, -4.7835e-01,  2.0139e-01, -1.0051e+00,\n",
            "         1.1515e-01, -9.6609e-01,  1.2960e-01,  1.8388e-01, -3.0383e-02])\n",
            "torch.Size([100])\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
            "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
            "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
            "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
            "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
            "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
            "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
            "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
            "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
            "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
            "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
            "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
            "        -0.3924, -0.2339,  0.4730, -0.0288])\n",
            "torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prints out the tokens and their embeddings. GloVe embeddings are PyTorch vectors of dimensionality 100.\n",
        "\n",
        "You choose which pre-trained embeddings you load by passing the appropriate id string to the constructor of the WordEmbeddings class. Typically, you use the two-letter language code to init an embedding, so 'en' for English and 'de' for German and so on. By default, this will initialize FastText embeddings trained over Wikipedia. You can also always use FastText embeddings over Web crawls, by instantiating with '-crawl'. So 'de-crawl' to use embeddings trained over German web crawls:"
      ],
      "metadata": {
        "id": "YWSdmjPc45sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "german_embedding = WordEmbeddings('de-crawl')"
      ],
      "metadata": {
        "id": "WFK-fEMY3czc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the full list of all word embeddings models here, along with more explanations on this class.\n",
        "\n",
        "We generally recommend the FastText embeddings, or GloVe if you want a smaller model."
      ],
      "metadata": {
        "id": "EPI7IYBM47pS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Flair Embeddings\n",
        "----\n",
        "Contextual string embeddings are powerful embeddings that capture latent syntactic-semantic information that goes beyond standard word embeddings. Key differences are: (1) they are trained without any explicit notion of words and thus fundamentally model words as sequences of characters. And (2) they are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use.\n",
        "\n",
        "With Flair, you can use these embeddings simply by instantiating the appropriate embedding class, same as standard word embeddings:"
      ],
      "metadata": {
        "id": "jkFhFRhB4_IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# init embedding\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "\n",
        "# create a sentence\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# embed words in sentence\n",
        "flair_embedding_forward.embed(sentence)"
      ],
      "metadata": {
        "id": "BmZSl1Hv3in8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init forward embedding for German\n",
        "flair_embedding_forward = FlairEmbeddings('de-forward')\n",
        "flair_embedding_backward = FlairEmbeddings('de-backward')"
      ],
      "metadata": {
        "id": "UhWlAURE3zye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You choose which embeddings you load by passing the appropriate string to the constructor of the FlairEmbeddings class. For all supported languages, there is a forward and a backward model. You can load a model for a language by using the two-letter language code followed by a hyphen and either forward or backward. So, if you want to load the forward and backward Flair models for German, do it like this:"
      ],
      "metadata": {
        "id": "yboELFdv5EJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the full list of all pre-trained FlairEmbeddings models here, along with more information on standard usage.\n",
        "\n",
        "##### Stacked Embeddings\n",
        "-----\n",
        "Stacked embeddings are one of the most important concepts of this library. You can use them to combine different embeddings together, for instance if you want to use both traditional embeddings together with contextual string embeddings. Stacked embeddings allow you to mix and match. We find that a combination of embeddings often gives best results.\n",
        "\n",
        "All you need to do is use the StackedEmbeddings class and instantiate it by passing a list of embeddings that you wish to combine. For instance, lets combine classic GloVe embeddings with forward and backward Flair embeddings. This is a combination that we generally recommend to most users, especially for sequence labeling.\n",
        "\n",
        "First, instantiate the two embeddings you wish to combine:"
      ],
      "metadata": {
        "id": "-W6pmP215GQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings\n",
        "\n",
        "# init standard GloVe embedding\n",
        "glove_embedding = WordEmbeddings(\"glove\")\n",
        "\n",
        "# init flair forward and backward embeddings\n",
        "flair_forward_embedding = FlairEmbeddings(\"news-forward\")\n",
        "flair_backward_embedding = FlairEmbeddings(\"news-backward\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QzKE_2-36pP",
        "outputId": "b03deb02-2dc4-4f1a-cc66-7a10fda4211b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:25:48,056 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpxrtps9wo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034624/73034624 [00:04<00:00, 16689320.06B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:25:52,908 copying /tmp/tmpxrtps9wo to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:25:53,101 removing temp file /tmp/tmpxrtps9wo\n",
            "2022-11-13 07:25:53,857 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpbn_rsn3r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 73034575/73034575 [00:04<00:00, 17869053.97B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:25:58,338 copying /tmp/tmpbn_rsn3r to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-13 07:25:58,481 removing temp file /tmp/tmpbn_rsn3r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now instantiate the StackedEmbeddings class and pass it a list containing these two embeddings."
      ],
      "metadata": {
        "id": "K8OOBtlQ5KwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "# create a StackedEmbedding object that combines glove and forward/backward flair embeddings\n",
        "stacked_embeddings = StackedEmbeddings([\n",
        "    glove_embedding,\n",
        "    flair_forward_embedding,\n",
        "    flair_backward_embedding,\n",
        "])"
      ],
      "metadata": {
        "id": "v6MlGnnE4UTm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! Now just use this embedding like all the other embeddings, i.e. call the embed() method over your sentences."
      ],
      "metadata": {
        "id": "GJj1wO3L5Mkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
        "stacked_embeddings.embed(sentence)\n",
        "\n",
        "# now check out the embedded tokens.\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)\n",
        "    print(token.embedding.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dHudk-m4mFk",
        "outputId": "dcd9f8e8-f40f-484c-9f15-199c5a0e6f3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-0.0382, -0.2449,  0.7281,  ..., -0.0065, -0.0053,  0.0090])\n",
            "torch.Size([4196])\n",
            "Token[1]: \"grass\"\n",
            "tensor([-0.8135,  0.9404, -0.2405,  ...,  0.0354, -0.0255, -0.0143])\n",
            "torch.Size([4196])\n",
            "Token[2]: \"is\"\n",
            "tensor([-5.4264e-01,  4.1476e-01,  1.0322e+00,  ..., -5.3691e-04,\n",
            "        -9.6750e-03, -2.7541e-02])\n",
            "torch.Size([4196])\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0007, -0.1333,  0.0161])\n",
            "torch.Size([4196])\n",
            "Token[4]: \".\"\n",
            "tensor([-0.3398,  0.2094,  0.4635,  ...,  0.0005, -0.0177,  0.0032])\n",
            "torch.Size([4196])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words are now embedded using a concatenation of three different embeddings. This means that the resulting embedding vector is still a single PyTorch vector.\n",
        "\n",
        "Next\n",
        "To get more details on these embeddings and a full overview of all word embeddings that we support, you can look into this tutorial. You can also skip details on word embeddings and go directly to document embeddings that let you embed entire text passages with one vector for tasks such as text classification. You can also go directly to the tutorial about loading your corpus, which is a pre-requirement for training your own models."
      ],
      "metadata": {
        "id": "kcWRnlqe5QTF"
      }
    }
  ]
}