{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDb Review Classification using CNN Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLuafex--R85"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lw6tgh8x_PO4"
      },
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh-wErRv_Qw_",
        "outputId": "fdd8b75f-f71d-4687-b821-dd924f1658f5"
      },
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  16.4M      0  0:00:04  0:00:04 --:--:-- 17.7M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqV4ZsR2_RaY"
      },
      "source": [
        "#### Dataset overview\n",
        "\n",
        "The `aclImdb` dir contains `train/` and `test/` dir. Each dir contains `pos` and `neg` dir. Each `pos` or `neg` dir contains multiple text file and each of them represents one sample (i.e., text only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RzCu4zH_QHg",
        "outputId": "b9cd1891-5ccb-4dc5-d2ad-ba0c7ce364aa"
      },
      "source": [
        "!ls ac*/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BkB1eDP_PRw",
        "outputId": "288a1032-aabb-4462-fc76-eb7788900566"
      },
      "source": [
        "!ls ac*/train/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck3Sk-KW_pgY",
        "outputId": "273611f0-00f3-404a-aacb-dd080cdedb2b"
      },
      "source": [
        "!cat ac*/train/pos/11694_7.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chris Rock stars in this remake of Warren Beatty's Heaven Can Wait (itself a remake of the 1941 film Here Comes Mr. Jordan), a comedy about a man who dies before his time, before he can realize his dreams, and his adventures in his new (albeit temporary) body. In the Beatty version, the protagonist was a backup quarterback for the then-Los Angeles Rams. In Rock's hipper version, our lead character is a struggling young - and decidedly low-talent - standup comedian.<br /><br />It's very funny to see the razor-sharp Rock playing a bad comedian. It's kind of like seeing Tom Hanks play a bad actor. Lance Barton's dream is to play the legendary Apollo Theater on a non-amateur night. But every time he tries out his material, he's booed off the stage lustily - so much so that his nickname becomes \"Booie.\" His jokes are lame, his delivery painful. In short, Lance is everything that the real Chris Rock isn't.<br /><br />Lance is also a bike messenger, and he's riding the streets on his way to try out even more material when BAM! He's hit by a truck. Ok, so maybe he was taken from his body a tenth of a second early by a slightly incompetent angel (Eugene Levy), but hey, he was going to get hit anyway. No dice, it appears Lance isn't due in Heaven until 2044. So what to do? Mr. King (Chazz Palminteri), the \"manager\" of Heaven, reluctantly agrees to find a new body for the not-quite-dead Mr. Barton. Trouble is, the body they find is of a greedy, old white man. Turns out this fella (a Mr. Wellington) owns all kinds of things - he's the 15th richest man in the country! What luck! You can imagine how Lance will turn things around. <br /><br />But of course, while in the body of the affluent Mr. Wellington, Lance falls for a gorgeous hospital worker (Regina King). We males know how tough it is to find a female given our own body, but try winning one over while you're an dumpy, old white guy! And it's even worse when she's not impressed by your money. <br /><br />This is Rock's first shot at a lead role, and in my opinion he performs admirably. There's still a lot of the standup comedian in him - and, of course, if he ever wants to get diverse roles, he might have to stop incorporating standup routines into the script - but this isn't really a bad thing. Rock's personality - his drive, his delivery, his demeanor, and his passion - are what fuel this film. He's clearly having a lot of fun in the role, and he seems bent on making sure you have fun watching him."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBXt6zwj_v9H"
      },
      "source": [
        "# remove unwanted dir \n",
        "!rm -r ac*/train/unsup"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDP61AI4AkOw"
      },
      "source": [
        "#### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PplNh1U6A1ju",
        "outputId": "2cf86316-18e8-498c-a1f3-b5c6ba69db81"
      },
      "source": [
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# set seed to prevent train/val set overlap\n",
        "\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "     validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42, \n",
        ")\n",
        "\n",
        "\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",    \n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUpRSXEWBxb_",
        "outputId": "232c7af7-0423-4643-a1d5-59d93a603033"
      },
      "source": [
        "print(f\"Number of batches in train_ds: {tf.data.experimental.cardinality(train_ds)}\")\n",
        "print(f\"Number of batches in val_ds: {tf.data.experimental.cardinality(val_ds)}\")\n",
        "print(f\"Number of batches in test_ds: {tf.data.experimental.cardinality(test_ds)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of batches in train_ds: 625\n",
            "Number of batches in val_ds: 157\n",
            "Number of batches in test_ds: 782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ELtT4WcCEa1"
      },
      "source": [
        "#### Preview batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R5-taGSCVP0",
        "outputId": "1748adc0-6e1c-41b8-c6f5-dbf166089503"
      },
      "source": [
        "for text, label in train_ds.take(1):\n",
        "    print(f\"Each batch contains {len(text)} samples\")\n",
        "    for i in range(3):\n",
        "        print(f\"Text: {text.numpy()[i]}\")\n",
        "        print(f\"Label: {label.numpy()[i]}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Each batch contains 32 samples\n",
            "Text: b\"Having seen most of Ringo Lam's films, I can say that this is his best film to date, and the most unusual. It's a ancient china period piece cranked full of kick-ass martial arts, where the location of an underground lair full of traps and dungeons plays as big a part as any of the characters. The action is fantastic, the story is tense and entertaining, and the set design is truely memorable. Sadly, Burning Paradise has not been made available on DVD and vhs is next-to-impossible to get your mitts on, even if you near the second biggest china-town in North America (like I do). If you can find it, don't pass it up.\"\n",
            "Label: 1\n",
            "Text: b'Caution: May contain spoilers...<br /><br />I\\'ve seen this movie 3 times & I\\'ve liked it every time. Upon seeing it again, I\\'m always reminded of how good it is. An HBO TV movie- very well done like most of their movies are- this would\\'ve gotten Oscars for it\\'s performances had it been released for general distribution instead of made for TV.<br /><br />As I\\'m sure anyone knows from reading other reviews here, this is the story of serial murderer, Andrei Chikatilo. He murdered 56 people over 8 years in the former Soviet Union. (3 victims were buried & couldn\\'t be found so he was only convicted of 52 out of 53 of his murders.) The story actually focuses more on the forensic analyst, Victor Burakov played to perfection by Stephen Rea. A man that becomes tortured and obsessed with finding this killer despite the additional obstacles placed by party hacks, his part is essential to be sure. There is a very touching scene towards the end of the movie that mentions how in America, investigators are routinely taken off serial killer cases after 18 months whether they want to or not due to the mental strain & frustration. According to this acct, Burakov worked for over 5 years before getting his first break from it. He followed the case to its conclusion, 3 years later. In this scene, his superior, General Fetisov, played by Donald Sutherland, actually tells him he admires his dedication and apologizes for not knowing he should\\'ve given him a break sooner.<br /><br />Rea\\'s performance is so well done, he doesn\\'t overact, chew up the scenery or do anything that distracts from his portrayal of a man who is hell bent on finding his killer. He is a man with passion, but doesn\\'t show it in the same manner as is so usually portrayed in detective movies. He only occasionally gives outbursts after quietly putting up with more than most could stand under such circumstances. Rea does so much with his face, his eyes, he doesn\\'t need to overact. He just *is* - His character, so frustrated after so long, at one point, driven to frustration, he actually says he\\'d rather find 3 at one time than none in a year. Of course what he means is not that he wants more people to die, he just wants some clues to catch this man. Rea makes us feel for this man. He makes us understand but a glimpse of what it is to live with such horror and futility.<br /><br />A mutant to be sure, Chikatilo\\'s childhood was one which produces such \"monsters.\" The character of Chikatilo is very well done by Jeffrey DeMunn. He somehow (impossible though it may seem) elicits some modicum of sympathy for himself. Perhaps he is the worst of us gone terribly wrong? Either way, his performance is very well done.<br /><br />Donald Sutherland as Colonel Fetisov (later promoted to General) also does a great job. He starts out seeming to be a cynical worldly official that doesn\\'t seem much more interested in helping the investigation than anyone else blocking Burakov. But he eventually becomes more than just an assistant, he actually actively participates in helping Burakov. There is also a very nice turn by Max Von Sydow as the psychiatrist brought in to help profile and figure out what kind of deviant they are looking for.<br /><br />Although this movie deals with a morbid, grotesque and violent story, it really is more about what it takes to catch a killer than the killer himself. All around a very well done movie with fine performances and a great screenplay. The screenplay manages to do what the best of this type of movie does: give factual events & place them meaningfully inside a dramatic framework that makes you feel like you know the people *behind* the facts.<br /><br />9 out of 10 stars'\n",
            "Label: 1\n",
            "Text: b\"from the view of a NASCAR Maniac like I am, the movie is interesting. You can see many race cars from 1983. Even tough, the racing scenes are not that much realistic. But I have to admit, that I haven't seen any race before 1995, because before that time, they didn't show any NASCAR races in Germany)<br /><br />from the view of a Burt Reynolds fan like I am, the movie basically is what we are used to see from Reynolds in the 80's: Burt behind the wheel of a fast car, like in his Bandit Movies.<br /><br />If you love NASCAR and Burt Reynolds, this movie is a must-see. If you only love one of this 2 things, I also recommend to watch it. If you like neither NASCAR nor Burt Reynolds, you still should give it a chance, but remember, this movie was far away from winning an Oscar Academy Award.<br /><br />It is the typical humor of the 80's. If you like movies like the Cannonball Movies, and Police Academy, you will also like that one.\"\n",
            "Label: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cpYJyKOCk8-"
      },
      "source": [
        "#### Basic text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davuKgk1FeTD"
      },
      "source": [
        "MAX_SEQ_LEN = 256\n",
        "EMBEDDING_SIZE = 300\n",
        "MAX_VOCAB_SIZE = 10000"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CUz9fmWCuQM"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.regex_replace(text, \"<br />\", \" \")\n",
        "    text = tf.strings.regex_replace(text, f\"[{string.punctuation}]\", \"\")\n",
        "    return text\n",
        "\n",
        "vectorized_layer = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=MAX_VOCAB_SIZE,\n",
        "    standardize=clean_text,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_SEQ_LEN,\n",
        ")\n",
        "\n",
        "train_text = train_ds.map(lambda x, y: x)\n",
        "# learn vocab from training set text\n",
        "vectorized_layer.adapt(train_text)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXe_zAB5GpFc",
        "outputId": "14a2e666-9d9b-4a8d-f114-b9ba5f64e26a"
      },
      "source": [
        "vectorized_layer.vocabulary_size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNY1eglMGxSx",
        "outputId": "c1bd5407-cd9b-4086-bf19-6dba18dd9772"
      },
      "source": [
        "print(vectorized_layer(\"This is a demo sentence.\"))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[  11    7    4    1 4320    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0], shape=(256,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhYNNInhG4tB"
      },
      "source": [
        "train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_ds  = val_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UamJOiMWH0z6"
      },
      "source": [
        "#### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1G1YWMFIDhA"
      },
      "source": [
        "def build_model():\n",
        "    input = tf.keras.Input(shape=(1,), dtype=\"string\", name=\"input_str_layer\")\n",
        "    x = vectorized_layer(input)\n",
        "    x = tf.keras.layers.Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=EMBEDDING_SIZE)(x)\n",
        "    x = tf.keras.layers.Conv1D(128, 3, activation=\"relu\", padding=\"valid\", strides=2)(x)\n",
        "    x = tf.keras.layers.Conv1D(256, 6, activation=\"relu\", padding=\"valid\", strides=2)(x)\n",
        "    x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=input, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        metrics=[tf.keras.metrics.BinaryAccuracy()]\n",
        "        )\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nslp7m79TWmo"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44yIjXlxT06R",
        "outputId": "e41ea66a-0ac2-4c19-8772-19feeba5b87f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_str_layer (InputLayer) [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 256, 300)          3000000   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 127, 128)          115328    \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 61, 256)           196864    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 3,378,241\n",
            "Trainable params: 3,378,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rllsV16sTrXH"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54asJrPbTye_",
        "outputId": "e13fd6d7-fa8f-45b5-f1d4-a7767f3e21a6"
      },
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    validation_data=val_ds,\n",
        "    verbose=1,\n",
        "    epochs=3,\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 119s 190ms/step - loss: 0.3288 - binary_accuracy: 0.8620 - val_loss: 0.3123 - val_binary_accuracy: 0.8632\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 117s 188ms/step - loss: 0.1609 - binary_accuracy: 0.9402 - val_loss: 0.4622 - val_binary_accuracy: 0.8388\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 116s 185ms/step - loss: 0.0959 - binary_accuracy: 0.9650 - val_loss: 0.4438 - val_binary_accuracy: 0.8554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ecf561dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqjQ2JdnUr2f"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc8sRb-oUal3",
        "outputId": "d6e12014-21d8-43b5-8b3a-67d3b036715f"
      },
      "source": [
        "model.evaluate(test_ds)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 35s 45ms/step - loss: 0.4656 - binary_accuracy: 0.8468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46564045548439026, 0.8467599749565125]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tbjax9ofWY39",
        "outputId": "cf72413c-a9ee-4d29-c61c-10e0e8063338"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'binary_accuracy']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBlfgLV6UvF_"
      },
      "source": [
        "#### Inferencing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJe1mGBaUySX",
        "outputId": "1724a771-b175-44b8-db3b-15cc97520502"
      },
      "source": [
        "test_sentence = tf.constant([\"Terrible movie. I hate this so much. No no. ugly so bad\"])\n",
        "\n",
        "predictions = model(test_sentence)\n",
        "\n",
        "print(f\"Text: {test_sentence}\")\n",
        "print(f\"Predictions: {predictions} ({'Positive' if predictions >= 0.5 else 'Negative'})\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: [b'Terrible movie. I hate this so much. No no. ugly so bad']\n",
            "Predictions: [[0.00513014]] (Negative)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoFQZhtYXiDm",
        "outputId": "a3889e8e-c2a2-4d15-d167-044105da8575"
      },
      "source": [
        "test_sentence = tf.constant([\"BEST movie. I love this so much.\"])\n",
        "\n",
        "predictions = model(test_sentence)\n",
        "\n",
        "print(f\"Text: {test_sentence}\")\n",
        "print(f\"Predictions: {predictions} ({'Positive' if predictions >= 0.5 else 'Negative'})\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text: [b'BEST movie. I love this so much.']\n",
            "Predictions: [[0.94804955]] (Positive)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}