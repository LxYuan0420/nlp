{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552ec552",
   "metadata": {},
   "source": [
    "# SetFit for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b96e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install setfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a8fcd-46fe-43e4-835e-57b84964358a",
   "metadata": {},
   "source": [
    "This notebook is designed to work with any multiclass [text classification dataset](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads) and pretrained [Sentence Transformer](https://huggingface.co/models?library=sentence-transformers&sort=downloads) on the Hub. Change the values below to try a different dataset / model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41542e15-d211-45e9-b428-e1532c525f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_id = \"banking77\"\n",
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {},
   "source": [
    "## Loading and sampling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cac8eff-fc55-4514-aa3e-d4ea4315827e",
   "metadata": {},
   "source": [
    "We will use the ðŸ¤— Datasets library to download the data, which can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a478f539-3867-4fc1-94ef-02b6dcc1676f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n",
      "Found cached dataset banking77 (/root/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005512714385986328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a24830a8c94c5b8b070649d6380fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(dataset_id)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa301d-51ec-4fe5-95c5-8a2e0aa2fb35",
   "metadata": {},
   "source": [
    "Most datasets on the Hub have many more labeled examples than those one encounters in few-shot settings. To simulate the effect of training on a limited number of examples, let's subsample the training set to have 8 labeled examples per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba671e5e-58f7-4d9e-aa82-8c0413b4a8df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 616\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import sample_dataset\n",
    "\n",
    "train_dataset = sample_dataset(dataset[\"train\"])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c609f71b-76b4-48d1-8024-08d16a713785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataset = dataset[\"test\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bd547-0e39-43ab-adf0-5f5509217020",
   "metadata": {},
   "source": [
    "Okay, now we have the dataset, let's load and train a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7c839-1f06-4d35-aa34-6e13659db814",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8c41a",
   "metadata": {},
   "source": [
    "To train a SetFit model, the first thing to do is download a pretrained checkpoint from the Hub. We can do so by using the `from_pretrained()` method associated with the `SetFitModel` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33661c9d-46d3-42eb-9b15-8a2bc49d7f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7521e-95ca-431a-8d7f-2f18e1de16ce",
   "metadata": {},
   "source": [
    "Here, we've downloaded a pretrained Sentence Transformer from the Hub and added a logistic classification head to the create the SetFit model. As indicated in the message, we need to train this model on some labeled examples. We can do so by using the `SetFitTrainer` class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44b7069-27b0-49ea-bc27-c44f94a98e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "from setfit import SetFitTrainer\n",
    "\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    #eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=20,\n",
    "    num_epochs=1,\n",
    "    batch_size=128,\n",
    "    column_mapping={\"text\": \"text\", \"label\": \"label\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3e642",
   "metadata": {},
   "source": [
    "The main arguments to notice in the trainer is the following:\n",
    "\n",
    "* `loss_class`: The loss function to use for contrastive learning with the Sentence Transformer body\n",
    "* `num_iterations`: The number of text pairs to generate for contrastive learning\n",
    "* `column_mapping`: The `SetFitTrainer` expects the inputs to be found in a `text` and `label` column. This mapping automatically formats the training and evaluation datasets for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3c5ae-c287-4936-b1ac-5eca10c7f39c",
   "metadata": {},
   "source": [
    "Now that we've created a trainer, we can train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d79e13b-37b1-4448-a7be-2bcc243b859d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to training dataset\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0046808719635009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Generating Training Pairs",
       "rate": null,
       "total": 20,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb25aaed300448d9cd101f3de8fac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Training Pairs:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 24640\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 193\n",
      "  Total train batch size = 128\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004208803176879883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Epoch",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3a1ac92ce442bfab8f7a84ce62c6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004163026809692383,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Iteration",
       "rate": null,
       "total": 193,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6a188d1a1c4832bf8a138ce64a5c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799f994",
   "metadata": {},
   "source": [
    "The final step is to compute the model's performance using the `evaluate()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc4e2515-9e01-4771-8615-51e035030789",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 3080\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf63e640-0fb7-45f6-89d3-4e4dd3902ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.eval_dataset = eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "453c11d0-a1e4-49c2-859a-cc70e033b4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to evaluation dataset\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004273891448974609,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading builder script",
       "rate": null,
       "total": 4203,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a347c87ccf64a8691f26b6f1df219fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8152597402597402}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a71155-20f7-45b8-b45b-026d5ff0f5ba",
   "metadata": {},
   "source": [
    "## Compare with open-source finetuned model from HF model hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4314f1c-4704-4d0b-b684-725ef2b9b7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005025386810302734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading (â€¦)okenizer_config.json",
       "rate": null,
       "total": 320,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491908692ef0458f9afdb96237ce1773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003885984420776367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading (â€¦)solve/main/vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8f80da044b4735ac60f9edf029a4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004850149154663086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading (â€¦)/main/tokenizer.json",
       "rate": null,
       "total": 711396,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e9959247f34cd186c3c068e3564c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007746219635009766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading (â€¦)cial_tokens_map.json",
       "rate": null,
       "total": 125,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53825801d1914d55acfea70bc616bb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007836103439331055,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading (â€¦)lve/main/config.json",
       "rate": null,
       "total": 5781,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc118f6e0b243878dbc0fcc6d8a5b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/5.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00499725341796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Downloading model.safetensors",
       "rate": null,
       "total": 268063276,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e89dc0a6661493eb331b583991c2470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lxyuan/banking-intent-distilbert-classifier\")\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(\"lxyuan/banking-intent-distilbert-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "009ac2f8-860b-43e0-bf5c-80798d37300b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aebe108-e094-47fe-b638-014a5f666164",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004495859146118164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 10003,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004146099090576172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 72,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 3080,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6630062-0e41-4e50-94f2-579d1020eb77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82bf22b8-3924-42ac-8797-dae1c96b98ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 18:54:46] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 18:54:46] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 18:54:46] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 18:54:46] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 18:54:46] No CPU tracking mode found. Falling back on CPU constant mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 18:54:47] We saw that you have a Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz but we don't know it. Please contact us.\n",
      "[codecarbon INFO @ 18:54:47] CPU Model on constant consumption mode: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz\n",
      "[codecarbon INFO @ 18:54:47] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 18:54:47]   Platform system: Linux-4.15.0-136-generic-x86_64-with-glibc2.27\n",
      "[codecarbon INFO @ 18:54:47]   Python version: 3.8.0\n",
      "[codecarbon INFO @ 18:54:47]   CodeCarbon version: 2.2.3\n",
      "[codecarbon INFO @ 18:54:47]   Available RAM : 88.490 GB\n",
      "[codecarbon INFO @ 18:54:47]   CPU count: 8\n",
      "[codecarbon INFO @ 18:54:47]   CPU model: Intel(R) Xeon(R) Gold 5220 CPU @ 2.20GHz\n",
      "[codecarbon INFO @ 18:54:47]   GPU count: 1\n",
      "[codecarbon INFO @ 18:54:47]   GPU model: 1 x Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "finetuned_trainer = Trainer(\n",
    "    model=finetuned_model,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8eca895c-2737-459c-8d1c-3705a59a1d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2885190546512604,\n",
       " 'eval_accuracy': 0.9243506493506494,\n",
       " 'eval_runtime': 3.0169,\n",
       " 'eval_samples_per_second': 1020.91,\n",
       " 'eval_steps_per_second': 127.614}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517c68b-c634-46c5-a855-a9fc90f1d9d3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Conclusion: Another good library to try when you have limited number training examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a53731e204626af339a5238c341a3f8c4bfd7cb5ccdda48ca3fe8366eef4175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
