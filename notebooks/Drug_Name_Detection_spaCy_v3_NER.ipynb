{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drug Name Detection spaCy v3 NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T0M5w6cya39",
        "outputId": "9bd796b2-10fb-453c-cb1b-f207459beddd"
      },
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "!pip install typer\n",
        "#!pip install spacy[cuda110]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 12.6 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 47.7 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.8\n",
            "  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
            "\u001b[K     |████████████████████████████████| 623 kB 26.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.0 pydantic-1.8.2 spacy-3.1.2 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.10 typer-0.3.2\n",
            "Collecting en-core-web-lg==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.1.0/en_core_web_lg-3.1.0-py3-none-any.whl (777.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 777.1 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-lg==3.1.0) (3.1.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (21.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.3.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (4.62.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-lg==3.1.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.7/dist-packages (0.3.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs8zORQKzznx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0156e86a-e1da-475c-98f8-e392ac03baf2"
      },
      "source": [
        "import spacy\n",
        "import srsly\n",
        "import pandas as pd\n",
        "spacy.prefer_gpu()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms4Miepu0cnR",
        "outputId": "8a64cd2c-cfa1-4362-f207-9fb087db25f7"
      },
      "source": [
        "# download training set\n",
        "!wget https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/assets/drugs_training.jsonl\n",
        "\n",
        "# download dev set\n",
        "!wget https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/assets/drugs_eval.jsonl\n",
        "\n",
        "# download script converting jsonl to .spacy format\n",
        "!wget https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/scripts/preprocess.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-19 03:11:35--  https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/assets/drugs_training.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3502481 (3.3M) [text/plain]\n",
            "Saving to: ‘drugs_training.jsonl’\n",
            "\n",
            "drugs_training.json 100%[===================>]   3.34M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-09-19 03:11:36 (97.5 MB/s) - ‘drugs_training.jsonl’ saved [3502481/3502481]\n",
            "\n",
            "--2021-09-19 03:11:36--  https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/assets/drugs_eval.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1194647 (1.1M) [text/plain]\n",
            "Saving to: ‘drugs_eval.jsonl’\n",
            "\n",
            "drugs_eval.jsonl    100%[===================>]   1.14M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-09-19 03:11:36 (50.1 MB/s) - ‘drugs_eval.jsonl’ saved [1194647/1194647]\n",
            "\n",
            "--2021-09-19 03:11:36--  https://raw.githubusercontent.com/explosion/projects/v3/tutorials/ner_drugs/scripts/preprocess.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 971 [text/plain]\n",
            "Saving to: ‘preprocess.py’\n",
            "\n",
            "preprocess.py       100%[===================>]     971  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-19 03:11:36 (28.4 MB/s) - ‘preprocess.py’ saved [971/971]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_d1FX0eLQPd"
      },
      "source": [
        "#### Convert JSONL to .spaCy format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqoIGBz3LKXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f4b80c-af12-4136-86e2-75e36d21246d"
      },
      "source": [
        "!python preprocess.py ./drugs_training.jsonl ./drugs_training.spacy\n",
        "!python preprocess.py ./drugs_eval.jsonl ./drugs_eval.spacy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1477 documents: drugs_training.spacy\n",
            "Processed 500 documents: drugs_eval.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mufwJOseImNI"
      },
      "source": [
        "#### Generate config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRROIn7LBL-K",
        "outputId": "5328e9d8-1174-4d41-c13b-56498f2a255f"
      },
      "source": [
        "!python -m spacy init config --lang en --pipeline ner configs/config.cfg --force --optimize accuracy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
            "install the spacy-transformers package and re-run this command. The config\n",
            "generated now does not use transformers.\u001b[0m\n",
            "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
            "- Language: en\n",
            "- Pipeline: ner\n",
            "- Optimize for: accuracy\n",
            "- Hardware: CPU\n",
            "- Transformer: None\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "configs/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j8TxjP3LGOr"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE57Xzsd1nVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f2596c-43ee-429b-af04-a1bdc09558ea"
      },
      "source": [
        "!python -m spacy train configs/config.cfg --output models/ --paths.train ./drugs_training.spacy --paths.dev ./drugs_eval.spacy --gpu-id 0 --components.tok2vec.model.encode.width 64 --components.tok2vec.model.encode.depth 4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Created output directory: models\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: models\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-09-19 03:16:53,617] [INFO] Set up nlp object from config\n",
            "[2021-09-19 03:16:53,630] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2021-09-19 03:16:53,635] [INFO] Created vocabulary\n",
            "[2021-09-19 03:18:00,793] [INFO] Added vectors: en_core_web_lg\n",
            "tcmalloc: large alloc 1643593728 bytes == 0x55eb4a536000 @  0x7ff2731552a4 0x7ff2616e8cb0 0x7ff2616f2083 0x7ff2616f187b 0x7ff2616eede1 0x7ff2616ef6de 0x55ea98f042ed 0x55ea98ff5e1d 0x55ea98f77e99 0x55ea98f729ee 0x55ea98f05bda 0x55ea98f74737 0x7ff127f52918 0x7ff127f541fe 0x7ff127f59947 0x7ff127f5ad42 0x55ea98f04c52 0x55ea98f77c25 0x55ea98f05afa 0x55ea98f73915 0x7ff127f52918 0x7ff127f541fe 0x7ff127f59470 0x55ea98f044b0 0x55ea98ff5e1d 0x55ea98f77e99 0x55ea98f72ced 0x55ea98f05bda 0x55ea98f74737 0x55ea98f72ced 0x55ea98f05bda\n",
            "tcmalloc: large alloc 1662509056 bytes == 0x55eb4a536000 @  0x7ff2731552a4 0x7ff2616e8cb0 0x7ff2616effcb 0x7ff2616f187b 0x7ff2616eede1 0x7ff2616ef6de 0x55ea98f042ed 0x55ea98ff5e1d 0x55ea98f77e99 0x55ea98f729ee 0x55ea98f05bda 0x55ea98f74737 0x55ea98f05afa 0x55ea98f77d00 0x7ff127f52918 0x7ff127f541fe 0x7ff127f59470 0x55ea98f044b0 0x55ea98ff5e1d 0x55ea98f77e99 0x55ea98f72ced 0x55ea98f05bda 0x55ea98f74737 0x55ea98f72ced 0x55ea98f05bda 0x55ea98f74737 0x55ea98f72ced 0x55ea98f05bda 0x55ea98f74737 0x55ea98f729ee 0x55ea98e44e2b\n",
            "[2021-09-19 03:18:03,238] [INFO] Finished initializing nlp object\n",
            "[2021-09-19 03:18:19,030] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     19.33    0.00    0.00    0.00    0.00\n",
            "  0     200         45.90    915.13   71.81   77.56   66.85    0.72\n",
            "  0     400         79.70    329.74   73.54   68.16   79.83    0.74\n",
            "  1     600        114.81    318.65   76.26   71.88   81.22    0.76\n",
            "  1     800        177.25    294.08   76.80   71.98   82.32    0.77\n",
            "  2    1000        178.17    295.62   78.64   80.58   76.80    0.79\n",
            "  3    1200        286.22    304.13   77.91   77.38   78.45    0.78\n",
            "  4    1400        425.44    329.65   79.89   78.61   81.22    0.80\n",
            "  5    1600        510.24    269.04   79.51   78.13   80.94    0.80\n",
            "  6    1800        475.67    252.49   78.06   76.12   80.11    0.78\n",
            "  8    2000       1064.04    221.29   77.82   74.94   80.94    0.78\n",
            " 10    2200        655.32    151.42   77.87   75.26   80.66    0.78\n",
            " 12    2400       3274.47    143.32   77.11   73.62   80.94    0.77\n",
            " 15    2600        428.25     99.97   77.34   73.15   82.04    0.77\n",
            " 18    2800        496.91     90.41   77.46   75.73   79.28    0.77\n",
            " 21    3000        292.56     45.24   77.99   78.65   77.35    0.78\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmyKmhOfLXJ3",
        "outputId": "4f82c0a6-10b5-4576-83a9-650b53a41d78"
      },
      "source": [
        "!python -m spacy evaluate ./models/model-last/ ./drugs_eval.spacy --gpu-id -1 --output evaluate.json"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     99.99\n",
            "NER P   78.65\n",
            "NER R   77.35\n",
            "NER F   77.99\n",
            "SPEED   34418\n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "DRUG   78.65   77.35   77.99\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to evaluate.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyRf2OpWKiHd"
      },
      "source": [
        "#### Retrain a new model focusing on Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTpGJtMLHZI1",
        "outputId": "0c800c8f-fed3-430b-a6e2-b642482a82b2"
      },
      "source": [
        "!python -m spacy train configs/config.cfg --output models_recall/ --paths.train ./drugs_training.spacy --paths.dev ./drugs_eval.spacy --gpu-id 0 --components.tok2vec.model.encode.width 64 --components.tok2vec.model.encode.depth 4 --training.score_weights.ents_r 1.0 --training.score_weights.ents_f 0.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: models_recall\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-09-19 03:38:19,151] [INFO] Set up nlp object from config\n",
            "[2021-09-19 03:38:19,164] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2021-09-19 03:38:19,169] [INFO] Created vocabulary\n",
            "[2021-09-19 03:38:46,218] [INFO] Added vectors: en_core_web_lg\n",
            "tcmalloc: large alloc 1643593728 bytes == 0x5620c314a000 @  0x7ff78559d2a4 0x7ff773b30cb0 0x7ff773b3a083 0x7ff773b3987b 0x7ff773b36de1 0x7ff773b376de 0x562043e7c2ed 0x562043f6de1d 0x562043eefe99 0x562043eea9ee 0x562043e7dbda 0x562043eec737 0x7ff63a397918 0x7ff63a3991fe 0x7ff63a39e947 0x7ff63a39fd42 0x562043e7cc52 0x562043eefc25 0x562043e7dafa 0x562043eeb915 0x7ff63a397918 0x7ff63a3991fe 0x7ff63a39e470 0x562043e7c4b0 0x562043f6de1d 0x562043eefe99 0x562043eeaced 0x562043e7dbda 0x562043eec737 0x562043eeaced 0x562043e7dbda\n",
            "tcmalloc: large alloc 1662509056 bytes == 0x5620c314a000 @  0x7ff78559d2a4 0x7ff773b30cb0 0x7ff773b37fcb 0x7ff773b3987b 0x7ff773b36de1 0x7ff773b376de 0x562043e7c2ed 0x562043f6de1d 0x562043eefe99 0x562043eea9ee 0x562043e7dbda 0x562043eec737 0x562043e7dafa 0x562043eefd00 0x7ff63a397918 0x7ff63a3991fe 0x7ff63a39e470 0x562043e7c4b0 0x562043f6de1d 0x562043eefe99 0x562043eeaced 0x562043e7dbda 0x562043eec737 0x562043eeaced 0x562043e7dbda 0x562043eec737 0x562043eeaced 0x562043e7dbda 0x562043eec737 0x562043eea9ee 0x562043dbce2b\n",
            "[2021-09-19 03:38:49,501] [INFO] Finished initializing nlp object\n",
            "[2021-09-19 03:38:52,323] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     19.33    0.00    0.00    0.00    0.00\n",
            "  0     200         45.90    915.13   71.81   77.56   66.85    0.67\n",
            "  0     400         80.11    330.20   73.51   67.92   80.11    0.80\n",
            "  1     600        118.03    315.11   76.37   71.02   82.60    0.83\n",
            "  1     800        191.50    301.06   75.10   69.83   81.22    0.81\n",
            "  2    1000        203.67    297.67   77.09   76.57   77.62    0.78\n",
            "  3    1200        407.85    306.40   78.56   78.67   78.45    0.78\n",
            "  4    1400        555.18    294.29   79.68   77.69   81.77    0.82\n",
            "  5    1600        410.87    276.61   77.58   77.26   77.90    0.78\n",
            "  6    1800        418.03    238.53   80.00   79.89   80.11    0.80\n",
            "  8    2000        584.06    211.66   73.64   67.75   80.66    0.81\n",
            " 10    2200       1329.42    171.97   78.04   77.09   79.01    0.79\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "models_recall/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkBgrTqZHr7N",
        "outputId": "53817520-252d-4cfa-d519-65178ad2b635"
      },
      "source": [
        "!python -m spacy evaluate ./models_recall/model-last/ ./drugs_eval.spacy --gpu-id -1 --output evaluate.json"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     99.99\n",
            "NER P   77.09\n",
            "NER R   79.01\n",
            "NER F   78.04\n",
            "SPEED   33034\n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "DRUG   77.09   79.01   78.04\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to evaluate.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdfN3E1Md3Pb"
      },
      "source": [
        "nlp = spacy.load(\"./models/model-last/\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw922n-SKpGO"
      },
      "source": [
        "data = srsly.read_jsonl(\"./drugs_eval.jsonl\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZxfXr5Qdert",
        "outputId": "6af4dad6-ecd2-4f2a-9976-e21e76450e3c"
      },
      "source": [
        "for idx in range(25):\n",
        "    test_case = next(data)\n",
        "    sentence = test_case[\"text\"] \n",
        "    doc = nlp(sentence)\n",
        "    y_pred = {ent: ent.text for ent in doc.ents}\n",
        "    print(f\"\\n\\n[Sentence]: \\n\\t{sentence}\")\n",
        "    print(f\"\\n[Predicted]: \\n\\t {y_pred}\")\n",
        "    print(\"-\"*100)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tagreed!\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tFuck man - shit is dry as balls where I am\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI believe with extensions it comes out to 120 days. More then likely you fell through the crack. As the lawyer above posted don't stir the pot.\n",
            "\n",
            "[Predicted]: \n",
            "\t {crack: 'crack', pot: 'pot'}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tjust use it with your dboy. by time he figures out its fake, if he even does... he won't know who gave it to him, so fuck it.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI'm paying about £18 for 200mg in the UK (darkweb). No idea what the purity is but it will be better than UK street gear, in general. 10$ for 80mg is very reasonable.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tSleep or binge watching shit on netflix. Waiting is the worst part of the game. A few hours feels like days.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tIt's okay, I pay 50$ for a quarter gram of heroin so I'm pretty much a complete fucking moron.\n",
            "\n",
            "[Predicted]: \n",
            "\t {heroin: 'heroin'}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tsum r sicker than others fam\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tOrange uncle monkey! Long time no see brotha. How you doing?\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tbeing depressed is human\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tright like I wouldn't even know *how* to hit myself\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tand on the third day he will rise again\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tA good one is get a hook that knows how to tell time. Nothing sketchier than waiting around for dude to hop in and out. Delivery is nice, but its got a whole lot of negatives of its own.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tThey are rapidly dismantled by the body, since the body has always been exposed to them\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tNeva slipping, just pimpin baby.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tWhen I said you I was referring not to you specifically, but instead you the general /r/opiates reader. Sorry for the confusion. It is popular to complain about shit posts or questions that can be easily answered with a simple Google search. As you (specifically) correctly pointed out, very little new content is posted to this sub daily. My point was to remind the good people of /r/opiates to remember this fact the next time they shit on someone's shit post. It may be garbage, but at least it is new garbage!\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tyea man I have some right now. Just got them off sheepmarket. Theyre good\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tIt's Canadian living. Some places in the country its like $50-$100 a point.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tAt the very bottom, enter your dosage from the last 10 days and it will spit out a taper, usually on a 60 day schedule\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI have done subutex and smoked fent a couple hours later. Now if it was sub oxen the cent might not have any effect. This is just from personal experience.\n",
            "\n",
            "[Predicted]: \n",
            "\t {subutex: 'subutex', fent: 'fent'}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tNo, I'm just putting the picture with the pajama comment above, and you sir got a onesie....prolly batman or big bird themed, can't decide\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tThis is the best snorting device in this thread. Also, poor Zimbabwe.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tWow! I'm *really* glad your friends arrived in time. I can't even imagine someone doing what that creep did - *that* should be criminal! Even if you *were* dead, if help arrived quickly enough, you still would have had a chance. Beyond skeevy. Thank you for the warning. I am so careless when it comes to measuring that stuff out - just dump, stir and shoot. I gotta knock that off if (when!) I do go for it again.\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tif this is the case i should have a cult by now XD\n",
            "\n",
            "[Predicted]: \n",
            "\t {}\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "[Sentence]: \n",
            "\tI have put #4 in my Vapor Bros box vape. I just made like a sammy of weed-heroin-weed in the bowl and it worked pretty well. However, I only did this once because I have friends who use my vape that do not get down with opiates. It was nice though.\n",
            "\n",
            "[Predicted]: \n",
            "\t {weed: 'weed', heroin: 'heroin', weed: 'weed', opiates: 'opiates'}\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqnHANrAeZ_F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}