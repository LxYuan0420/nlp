{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0d3d700-80a4-4e69-a548-ca39cb68ce9e",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "\n",
    "This Jupyter Notebook aims to build and evaluate a multilabel text classification model using Scikit-Learn libraries. The focus is on classifying news articles into multiple topics or categories. Given that we are working in a client-facing environment, the primary metric of interest is precision, to minimize false positives and maintain client trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1de50f3-2b02-4153-9847-5936249fd12f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/likxun/mynotebooks/env38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97850683-313b-4aac-b673-70c15f04aa93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"Remove numbers, newlines, and special characters from text.\"\"\"\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Find Single Appearance Labels\n",
    "def find_single_appearance_labels(y):\n",
    "    \"\"\"Find labels that appear only once in the dataset.\"\"\"\n",
    "    all_labels = list(chain.from_iterable(y))\n",
    "    label_count = Counter(all_labels)\n",
    "    single_appearance_labels = [label for label, count in label_count.items() if count == 1]\n",
    "    return single_appearance_labels\n",
    "\n",
    "# Remove Single Appearance Labels from Dataset\n",
    "def remove_single_appearance_labels(dataset, single_appearance_labels):\n",
    "    \"\"\"Remove samples with single-appearance labels from both train and test sets.\"\"\"\n",
    "    for split in ['train', 'test']:\n",
    "        dataset[split] = dataset[split].filter(lambda x: all(label not in single_appearance_labels for label in x['topics']))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6002ceb-50bc-4cce-843a-35ff6b23fa73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding single appearance labels...\n",
      "Single appearance labels: ['lin-oil', 'rye', 'red-bean', 'groundnut-oil', 'citruspulp', 'rape-meal', 'corn-oil', 'peseta', 'cotton-oil', 'ringgit', 'castorseed', 'castor-oil', 'lit', 'rupiah', 'skr', 'nkr', 'dkr', 'sun-meal', 'lin-meal', 'cruzado']\n",
      "Removing samples with single-appearance labels...\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "dataset = load_dataset(\"reuters21578\", \"ModApte\")\n",
    "\n",
    "# Find and Remove Single Appearance Labels\n",
    "print(\"Finding single appearance labels...\")\n",
    "y_train = [item['topics'] for item in dataset['train']]\n",
    "single_appearance_labels = find_single_appearance_labels(y_train)\n",
    "print(f\"Single appearance labels: {single_appearance_labels}\")\n",
    "\n",
    "print(\"Removing samples with single-appearance labels...\")\n",
    "dataset = remove_single_appearance_labels(dataset, single_appearance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8105d013-2790-4049-a1e1-ce7d536de1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n"
     ]
    }
   ],
   "source": [
    "# Combine title and text, then preprocess\n",
    "print(\"Preprocessing text...\")\n",
    "X_train = [item['title'] + ' ' + item['text'] for item in dataset['train']]\n",
    "X_train = [preprocess_text(text) for text in X_train]\n",
    "y_train = [item['topics'] for item in dataset['train']]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform Labels to Binary Matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_bin = mlb.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b79a9e-3816-4889-ad5b-43e0dcf52f90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/likxun/mynotebooks/env38/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['cottonseed', 'f-cattle', 'sfr'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test_tfidf = vectorizer.transform([preprocess_text(item['title'] + ' ' + item['text']) for item in dataset['test']])\n",
    "y_test_bin = mlb.transform([item['topics'] for item in dataset['test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bef7aed-9999-496d-b5dc-69be02288370",
   "metadata": {},
   "source": [
    "Note: Using scikit-learn's MultiLabelBinarizer is convenient because it automatically disregards any labels in the test set that didn't appear during training. However, when employing transformer models, additional preprocessing steps are needed to manage these unseen labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c81e003-944e-4918-afc1-79b4d40341d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acq', 'alum', 'austdlr', 'barley', 'bop', 'can', 'carcass',\n",
       "       'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper',\n",
       "       'copra-cake', 'corn', 'cornglutenfeed', 'cotton', 'cpi', 'cpu',\n",
       "       'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fishmeal', 'fuel', 'gas',\n",
       "       'gnp', 'gold', 'grain', 'groundnut', 'heat', 'hog', 'housing',\n",
       "       'income', 'instal-debt', 'interest', 'inventories', 'ipi',\n",
       "       'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'linseed',\n",
       "       'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply',\n",
       "       'naphtha', 'nat-gas', 'nickel', 'nzdlr', 'oat', 'oilseed',\n",
       "       'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem',\n",
       "       'platinum', 'plywood', 'pork-belly', 'potato', 'propane', 'rand',\n",
       "       'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber',\n",
       "       'saudriyal', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil',\n",
       "       'soybean', 'stg', 'strategic-metal', 'sugar', 'sun-oil', 'sunseed',\n",
       "       'tapioca', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wool',\n",
       "       'wpi', 'yen', 'zinc'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d020f179-58b8-4650-ab8c-e58d6a691904",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Train Classifier\n",
    "print(\"Training classifier...\")\n",
    "#clf = OneVsRestClassifier(MultinomialNB())\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "clf.fit(X_train_tfidf, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf52feb-6dfb-4bff-bf19-5c73426e2746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions and evaluating...\n"
     ]
    }
   ],
   "source": [
    "# Predictions and Evaluation\n",
    "print(\"Making predictions and evaluating...\")\n",
    "y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2585c3-0668-4500-8ef5-72c501a9c8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "            acq       0.98      0.87      0.92       719\n",
      "           alum       1.00      0.00      0.00        23\n",
      "        austdlr       1.00      1.00      1.00         0\n",
      "         barley       1.00      0.00      0.00        12\n",
      "            bop       1.00      0.30      0.46        30\n",
      "            can       1.00      1.00      1.00         0\n",
      "        carcass       1.00      0.06      0.11        18\n",
      "          cocoa       1.00      0.61      0.76        18\n",
      "        coconut       1.00      0.00      0.00         2\n",
      "    coconut-oil       1.00      0.00      0.00         2\n",
      "         coffee       0.94      0.59      0.73        27\n",
      "         copper       1.00      0.22      0.36        18\n",
      "     copra-cake       1.00      0.00      0.00         1\n",
      "           corn       0.97      0.51      0.67        55\n",
      " cornglutenfeed       1.00      1.00      1.00         0\n",
      "         cotton       1.00      0.06      0.11        18\n",
      "            cpi       1.00      0.14      0.25        28\n",
      "            cpu       1.00      0.00      0.00         1\n",
      "          crude       0.94      0.69      0.80       189\n",
      "            dfl       1.00      0.00      0.00         1\n",
      "            dlr       0.86      0.43      0.58        44\n",
      "            dmk       1.00      0.00      0.00         4\n",
      "           earn       0.99      0.97      0.98      1087\n",
      "       fishmeal       1.00      1.00      1.00         0\n",
      "           fuel       1.00      0.00      0.00        10\n",
      "            gas       1.00      0.00      0.00        17\n",
      "            gnp       1.00      0.31      0.48        35\n",
      "           gold       0.83      0.17      0.28        30\n",
      "          grain       1.00      0.65      0.79       146\n",
      "      groundnut       1.00      0.00      0.00         4\n",
      "           heat       1.00      0.00      0.00         5\n",
      "            hog       1.00      0.00      0.00         6\n",
      "        housing       1.00      0.00      0.00         4\n",
      "         income       1.00      0.00      0.00         7\n",
      "    instal-debt       1.00      0.00      0.00         1\n",
      "       interest       0.88      0.40      0.55       131\n",
      "    inventories       1.00      1.00      1.00         0\n",
      "            ipi       1.00      0.00      0.00        12\n",
      "     iron-steel       1.00      0.00      0.00        14\n",
      "            jet       1.00      0.00      0.00         1\n",
      "           jobs       1.00      0.14      0.25        21\n",
      "       l-cattle       1.00      0.00      0.00         2\n",
      "           lead       1.00      0.00      0.00        14\n",
      "            lei       1.00      0.00      0.00         3\n",
      "        linseed       1.00      1.00      1.00         0\n",
      "      livestock       0.67      0.08      0.15        24\n",
      "         lumber       1.00      0.00      0.00         6\n",
      "      meal-feed       1.00      0.00      0.00        17\n",
      "       money-fx       0.80      0.50      0.62       177\n",
      "   money-supply       0.88      0.41      0.56        34\n",
      "        naphtha       1.00      0.00      0.00         4\n",
      "        nat-gas       1.00      0.27      0.42        30\n",
      "         nickel       1.00      0.00      0.00         1\n",
      "          nzdlr       1.00      0.00      0.00         2\n",
      "            oat       1.00      0.00      0.00         4\n",
      "        oilseed       0.62      0.11      0.19        44\n",
      "         orange       1.00      0.00      0.00        11\n",
      "      palladium       1.00      0.00      0.00         1\n",
      "       palm-oil       1.00      0.22      0.36         9\n",
      "     palmkernel       1.00      0.00      0.00         1\n",
      "       pet-chem       1.00      0.00      0.00        12\n",
      "       platinum       1.00      0.00      0.00         7\n",
      "        plywood       1.00      1.00      1.00         0\n",
      "     pork-belly       1.00      1.00      1.00         0\n",
      "         potato       1.00      0.00      0.00         3\n",
      "        propane       1.00      0.00      0.00         3\n",
      "           rand       1.00      0.00      0.00         1\n",
      "       rape-oil       1.00      0.00      0.00         1\n",
      "       rapeseed       1.00      0.00      0.00         8\n",
      "       reserves       1.00      0.00      0.00        18\n",
      "         retail       1.00      0.00      0.00         2\n",
      "           rice       1.00      0.00      0.00        23\n",
      "         rubber       1.00      0.17      0.29        12\n",
      "      saudriyal       1.00      1.00      1.00         0\n",
      "           ship       0.92      0.26      0.40        89\n",
      "         silver       1.00      0.00      0.00         8\n",
      "        sorghum       1.00      0.00      0.00         8\n",
      "       soy-meal       1.00      0.00      0.00        12\n",
      "        soy-oil       1.00      0.00      0.00         8\n",
      "        soybean       1.00      0.16      0.27        32\n",
      "            stg       1.00      1.00      1.00         0\n",
      "strategic-metal       1.00      0.00      0.00        11\n",
      "          sugar       1.00      0.60      0.75        35\n",
      "        sun-oil       1.00      1.00      1.00         0\n",
      "        sunseed       1.00      0.00      0.00         5\n",
      "        tapioca       1.00      1.00      1.00         0\n",
      "            tea       1.00      0.00      0.00         3\n",
      "            tin       1.00      0.00      0.00        12\n",
      "          trade       0.92      0.61      0.74       116\n",
      "        veg-oil       1.00      0.12      0.21        34\n",
      "          wheat       0.97      0.55      0.70        69\n",
      "           wool       1.00      1.00      1.00         0\n",
      "            wpi       1.00      0.00      0.00        10\n",
      "            yen       1.00      0.00      0.00        14\n",
      "           zinc       1.00      0.00      0.00        13\n",
      "\n",
      "      micro avg       0.97      0.64      0.77      3694\n",
      "      macro avg       0.98      0.25      0.29      3694\n",
      "   weighted avg       0.96      0.64      0.70      3694\n",
      "    samples avg       0.98      0.74      0.75      3694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_bin, y_pred, target_names=mlb.classes_, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ede1c-54cb-4624-a038-29348dc47eea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Insight:\n",
    "\n",
    "- In our client-facing news classification model, precision takes precedence over recall. This is because the repercussions of false positives are more severe and harder to justify to clients compared to false negatives. When the model incorrectly tags a news item with a topic, it's challenging to explain this error. On the other hand, if the model misses a topic, it's easier to defend by stating that the topic wasn't sufficiently emphasized in the news article.\n",
    "\n",
    "- High Precision, Low Recall: The model seems to be cautious, making predictions only when it is highly certain. This is good for avoiding false positives but at the cost of missing several true positives, leading to low recall.\n",
    "\n",
    "- Macro vs Micro Averages: The micro avg F1-score is 0.77, which is decent, but the macro avg F1-score is 0.29, which is low. This discrepancy indicates that while the model performs well on commonly occurring labels, it fails to capture the minority classes effectively.\n",
    "\n",
    "- Labels with Zero Support: There are several labels where the 'support' is zero, meaning they did not appear in the test set. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
